{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Exploring Hypothesis Testing: A Series for Beginners'\n",
        "---"
      ],
      "id": "71f14853"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Understanding\n",
        "### 2.1 Donwload data from Kaggle\n"
      ],
      "id": "c52a8f06"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats"
      ],
      "id": "800a29cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download dataset\n"
      ],
      "id": "f27c20d9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from kaggle import KaggleApi\n",
        "import os\n",
        "\n",
        "# Nombre del archivo del dataset en Kaggle\n",
        "dataset_name = \"bestsellers with categories.csv\"\n",
        "# ID del dataset en Kaggle\n",
        "dataset_id = \"sootersaalu/amazon-top-50-bestselling-books-2009-2019/\"\n",
        "\n",
        "# Directorio de destino\n",
        "download_path = \"./data/\"\n",
        "\n",
        "# Verificar si el archivo ya existe en la carpeta de destino\n",
        "list_of_files = os.listdir(download_path)\n",
        "if any(dataset_name in filename for filename in list_of_files):\n",
        "    print(\"El archivo ya existe \" + download_path)\n",
        "else:\n",
        "    # Autenticar con la API de Kaggle\n",
        "    api = KaggleApi()\n",
        "    api.authenticate()\n",
        "\n",
        "    # Descargar el dataset\n",
        "    api.dataset_download_files(dataset_id, path=download_path, unzip=True)"
      ],
      "id": "d6720da9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Data description\n"
      ],
      "id": "c61154eb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_csv(download_path + dataset_name)\n",
        "df.head(30)"
      ],
      "id": "6cbed231",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Name\n",
        "  - Título del libro\n",
        "  - Unidad: texto (categoría)\n",
        "- Author\n",
        "  - Nombre del autor\n",
        "  - Unidad: texto (categoría)\n",
        "- User Rating\n",
        "  - Calificación promedio del libro por los usuarios\n",
        "  - Unidad: número entre 0 y 5 (con decimales)\n",
        "- Reviews\n",
        "  - Número de reseñas\n",
        "  - Unidad: número entero\n",
        "- Price\n",
        "  - Precio del libro\n",
        "  - Unidad: número entero\n",
        "- Year\n",
        "  - Año en el que el libro fue de los más vendidos\n",
        "  - Unidad: año (número entero)\n",
        "- Genre\n",
        "  - Género del libro simplificado (Fiction o Non Fiction)\n",
        "  - Unidad: categorico con dos valores posibles\n",
        "\n",
        "## 3. Data preparation\n",
        "\n",
        "### 3.1 Typecasting\n",
        "\n",
        "## 1. Business Understanding\n",
        "\n",
        "dataset source: https://www.kaggle.com/datasets/sootersaalu/amazon-top-50-bestselling-books-2009-2019/data\n",
        "\n",
        "### Context\n",
        "Datos sobre los 50 libros más vendidos en Amazon de 2009 a 2019. \n",
        "\n",
        "### Hypothesis to Test\n",
        "\n",
        "Vamos a responder a las siguientes preguntas con validez estadística:\n",
        "\n",
        "- ¿Los géneros difieren en User Rating?\n",
        "- ¿Los géneros difieren en número de Reviews?\n",
        "- ¿Los géneros difieren en términos de precio?\n"
      ],
      "id": "9259f0ba"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# comprobamos el tipo de datos de las columnas\n",
        "df.dtypes"
      ],
      "id": "f4dd8a9a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "columnas_categoricas = [\"Genre\", \"Name\", \"Author\"]\n",
        "df[columnas_categoricas] = df[columnas_categoricas].astype(\"category\")"
      ],
      "id": "be490327",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.dtypes"
      ],
      "id": "296e264f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Handling Duplicates\n",
        "\n",
        "Comprobar si hay autores o títulos iguales pero escritos diferente.\n"
      ],
      "id": "1da33052"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "\n",
        "# Función para encontrar nombres de autores similares\n",
        "def encontrar_similares(df, columna):\n",
        "    autores = df[columna].unique()\n",
        "    duplicados = []\n",
        "\n",
        "    for i, autor1 in enumerate(autores):\n",
        "        for autor2 in autores[i + 1 :]:\n",
        "            ratio = fuzz.ratio(autor1, autor2)\n",
        "            if ratio > 90:  # Puedes ajustar este umbral según tu criterio\n",
        "                duplicados.append((autor1, autor2))\n",
        "\n",
        "    return duplicados\n"
      ],
      "id": "4fa75fae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Encuentra nombres de autores similares\n",
        "duplicados = encontrar_similares(df, \"Author\")\n",
        "\n",
        "print(\n",
        "    \"Nombres de autores que se refieren al mismo autor pero están escritos diferente:\"\n",
        ")\n",
        "for dup in duplicados:\n",
        "    print(dup)"
      ],
      "id": "daa2c5b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Replace the names of the Authors with the correct ones\n",
        "df = df.replace(\"George R. R. Martin\", \"George R.R. Martin\")\n",
        "df = df.replace(\"J. K. Rowling\", \"J.K. Rowling\")"
      ],
      "id": "93e4f8a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Encuentra nombres de títulos similares\n",
        "duplicados = encontrar_similares(df, \"Name\")\n",
        "\n",
        "print(\n",
        "    \"Nombres de autores que se refieren al mismo autor pero están escritos diferente:\"\n",
        ")\n",
        "for dup in duplicados:\n",
        "    print(dup)"
      ],
      "id": "7bf7776d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Replace the names of the Authors with the correct ones\n",
        "df = df.replace(\n",
        "    \"The 5 Love Languages: The Secret to Love That Lasts\",\n",
        "    \"The 5 Love Languages: The Secret to Love that Lasts\",\n",
        ")\n",
        "df = df.replace(\n",
        "    \"The Girl Who Played with Fire (Millennium Series)\",\n",
        "    \"The Girl Who Played with Fire (Millennium)\",\n",
        ")"
      ],
      "id": "0229fbcc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df"
      ],
      "id": "b4e78ceb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# número de filas duplicadas\n",
        "df.duplicated().sum()"
      ],
      "id": "cf2b9d88",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Es normal no encontrar duplicados en este caso, hay libros que se repiten pero es imposible que coincidan en \"Year\". No es un error por si mismo. Pero hay un problema. Las \"Reviews\" deberían ser las que el libro tenia el año en el que fue de los mas vendidos. En lugar de eso son las del último año. Esto puede deberse a que el autor del dataset no tuvo acceso al historial de las reseñas.\n",
        "\n",
        "Es importante tener en cuenta esto para el análisis.\n",
        "\n",
        "Vamos a utilizar unicamente la muestra más reciente de cada libro.\n"
      ],
      "id": "bc4ab067"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# todos los libros con el titulo repetido\n",
        "df[df.duplicated(\"Name\")].head(20)"
      ],
      "id": "3a5455d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Drop duplicates\n",
        "bestsellers = df.drop_duplicates(subset=\"Name\", keep=\"last\")\n",
        "bestsellers"
      ],
      "id": "897b6d64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resumen:\n",
        "- Hemos corregido los errores ortográficos de los títulos y autores.\n",
        "- Hemos seleccionado las muestras más recientes de cada libro.\n",
        "\n",
        "Hemos reducido el tamaño del dataset de 550 a 349 muestras.\n",
        "\n",
        "### 3.3 Outlier Analysis\n",
        "\n",
        "#### 3.3.2 Usando boxplot y IQR \n",
        "IQR: El rango intercuartil (IQR) es la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1). Los valores que caen por debajo de Q1 - 1.5 * IQR o por encima de Q3 + 1.5 * IQR se consideran outliers.\n",
        "\n",
        "Los valores fuera del de este rango, son los que se representa como puntos en los bloxpots.\n"
      ],
      "id": "56b07aed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import plotly.express as px\n",
        "\n",
        "selected_columns = [\"Reviews\", \"Price\"]\n",
        "\n",
        "for column in selected_columns:\n",
        "    fig = px.box(df, x=column, title=f\"Boxplot of {column}\")\n",
        "    fig.update_layout(title_x=0.5)  # Centra el título\n",
        "    fig.show()"
      ],
      "id": "6d9d35ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observaciones:\n",
        "\n",
        "- age: no se detectan outliers\n",
        "- BMI: existen outliers, personas con una alta obesidad\n",
        "- charges: existen outliers, personas con cargos muy altos al seguro\n",
        "\n",
        "### 3.4 Zero & Near Zero Variance Features\n"
      ],
      "id": "dc443fe4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bestsellers.describe()"
      ],
      "id": "569dddc4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Variables númericas\n"
      ],
      "id": "956e08d9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "selected_columns = [\"User Rating\", \"Reviews\", \"Price\"]\n",
        "\n",
        "# Calcular la varianza de cada columna\n",
        "variances = bestsellers[selected_columns].var()\n",
        "\n",
        "# Definir un umbral para la varianza\n",
        "threshold = 0.1\n",
        "\n",
        "# Identificar las columnas con varianza cercana a cero o muy pequeña\n",
        "zero_variance_cols = variances[variances <= threshold].index\n",
        "\n",
        "print(\"Columnas con Zero & Near Zero Variance:\")\n",
        "print(zero_variance_cols)"
      ],
      "id": "720cb9aa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Variables categoricas. No tiene sentido en este analisis en este caso.\n",
        "\n",
        "Observiaciones:\n",
        "\n",
        "- No se detectan variables con Zero & Near Zero Variance\n",
        "\n",
        "### 3.5 Missing values\n"
      ],
      "id": "c8140076"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bestsellers.isnull().sum()"
      ],
      "id": "c3c5f9ae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observiaciones:\n",
        "\n",
        "- No hay Missing values\n",
        "\n",
        "# 4. Hipothesis Testing\n",
        "\n",
        "Vamos a responder a las siguientes preguntas con validez estadística:\n",
        "- ¿Los géneros difieren en User Rating?\n",
        "- ¿Los géneros difieren en número de Reviews?\n",
        "- ¿Los géneros difieren en términos de precio?\n",
        "\n",
        "## ¿Los géneros difieren en User Rating?\n",
        "\n",
        "Vamos a crear una variable para cada grupo de interes y representarlos gráficamente.\n"
      ],
      "id": "18c8fbe6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fiction_bestsellers = bestsellers[bestsellers[\"Genre\"] == \"Fiction\"]\n",
        "nonfiction_bestsellers = bestsellers[bestsellers[\"Genre\"] == \"Non Fiction\"]"
      ],
      "id": "06061a7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.kdeplot(fiction_bestsellers[\"User Rating\"], fill=True, color=\"r\")\n",
        "sns.kdeplot(nonfiction_bestsellers[\"User Rating\"], fill=True, color=\"b\")\n",
        "plt.legend([\"Fiction\", \"Non Fiction\"])\n",
        "plt.xlabel(\"User Rating\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.show()"
      ],
      "id": "ac69385e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calcular el coeficiente de asimetría\n",
        "skewness = stats.skew(bestsellers[\"User Rating\"])\n",
        "print(\"Coeficiente de asimetría:\", skewness)\n",
        "\n",
        "if skewness > 0:\n",
        "    print(\"La distribución está positivamente sesgada.\")\n",
        "elif skewness < 0:\n",
        "    print(\"La distribución está negativamente sesgada.\")\n",
        "else:\n",
        "    print(\"La distribución es simétrica.\")"
      ],
      "id": "133b6bad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Número de observaciones para cada grupo:\n"
      ],
      "id": "a65bb91e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bestsellers[\"Genre\"].value_counts()"
      ],
      "id": "47d4ac05",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realizamos un test de normalidad para cada grupo:\n"
      ],
      "id": "b424d983"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from scipy import stats\n",
        "\n",
        "\n",
        "def shapiro_test(data, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Realiza la prueba de Shapiro-Wilk para verificar la normalidad de los datos.\n",
        "\n",
        "    Parameters:\n",
        "    data (array-like): Los datos a analizar.\n",
        "    alpha (float): Nivel de significancia.\n",
        "\n",
        "    Returns:\n",
        "    str: El resultado de la prueba.\n",
        "    \"\"\"\n",
        "    statistic, p_value = stats.shapiro(data)\n",
        "\n",
        "    if p_value < alpha:\n",
        "        return (\n",
        "            \"Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\"\n",
        "        )\n",
        "    else:\n",
        "        return \"Fallamos al rechazar la hipótesis nula. Los datos pueden considerarse normalmente distribuidos.\"\n",
        "\n",
        "\n",
        "result_fiction = shapiro_test(fiction_bestsellers[\"User Rating\"])\n",
        "result_nonfiction = shapiro_test(nonfiction_bestsellers[\"User Rating\"])\n",
        "\n",
        "print(\"Para bestsellers de ficción:\", result_fiction)\n",
        "print(\"Para bestsellers de no ficción:\", result_nonfiction)"
      ],
      "id": "f03bf86c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estudiemos la relación entre las varianzas de cada grupo.\n"
      ],
      "id": "b9653a67"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Realiza el Test de Levene\n",
        "statistic, p_value = stats.levene(\n",
        "    fiction_bestsellers[\"User Rating\"], nonfiction_bestsellers[\"User Rating\"]\n",
        ")\n",
        "\n",
        "# Nivel de significancia\n",
        "alpha = 0.05\n",
        "\n",
        "# Comprueba la significancia\n",
        "if p_value < alpha:\n",
        "    print(\"Rechazamos la hipótesis nula. Las varianzas no son similares\")\n",
        "else:\n",
        "    print(\"Fallamos al rechazar la hipótesis nula. Las varianzas son similares\")"
      ],
      "id": "f2fb77d3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# varianza de los grupos\n",
        "bestsellers.groupby([\"Genre\"])[\"User Rating\"].var()"
      ],
      "id": "035b5a2f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Seleccionamos la hipotesis y el nivel de significancia\n",
        "\n",
        "H0: El \"User Rating\" de los libros de ficción es igual que el de los libros de no ficción\n",
        "\n",
        "Ha: El \"User Rating\" de los libros de ficción es diferente que el de los libros de no ficción\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "### 2. Identificamos el tipo de test\n",
        "\n",
        "Deseamos comparar las medias de dos grupos de nuestra Sample. Por lo que un 2-Sample t-Test parece lo adecuado. Lo primero es ver si se cumplen los requisitos del test.\n",
        "\n",
        "#### 2.1 Requisitos del test\n",
        "[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\n",
        "Page: 48\n",
        "Section: 2-Sample t-Tests]\n",
        "- Tenemos un Sample representativo de la población? Si.\n",
        "- Los datos son continuos? \n",
        "  - En este contexto, los \"User Rating\" que van de 0 a 5 con un único decimal pueden considerarse como datos continuos. Sim embargo, observando las gráficas, vemos que la mayoría de los valores se encuetran en un intervalor muy pequeño (mayores a 4.0). Esto dificulta el poder considerarlo continuos.\n",
        "- Las muestras siguen una distribución normal o hay más de 15 observaciones\n",
        "  - No, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema del límite central podemos renunciar al supuesto de normalidad.\n",
        "- Los grupos son independientes? Si.\n",
        "- Las varianzas son iguales (o al menos similares)?\n",
        "  - No.\n",
        "\n",
        "\n",
        "Por la falta de continuidad en los datos, vamos a realizar un **test no paramétrico Mann-Whitney**.\n",
        "\n",
        "[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\n",
        "Page: 341\n",
        "Section: Analyzing Likert Scale Data]\n",
        "\n",
        "Para realizar el test vamos a usar [scipy.stats.mannwhitneyu](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html)\n"
      ],
      "id": "ba8b34bd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Realiza el test de Mann-Whitney\n",
        "statistic, p_value = stats.mannwhitneyu(\n",
        "    nonfiction_bestsellers[\"User Rating\"], fiction_bestsellers[\"User Rating\"]\n",
        ")\n",
        "\n",
        "# Imprime los resultados\n",
        "print(\"Valor p:\", p_value)\n",
        "\n",
        "# Comprueba la significancia\n",
        "alpha = 0.05  # Nivel de significancia\n",
        "if p_value < alpha:\n",
        "    print(\n",
        "        \"Rechazamos la hipótesis nula. Hay diferencias significativas entre los grupos.\"\n",
        "    )\n",
        "else:\n",
        "    print(\n",
        "        \"Fallamos al rechazar la hipótesis nula. No hay diferencias significativas entre los grupos.\"\n",
        "    )"
      ],
      "id": "7b19a2ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ¿Los géneros difieren en número de Reviews?\n",
        "\n",
        "Representamos gráficamente los grupos de interés.\n"
      ],
      "id": "8d2b6021"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.kdeplot(fiction_bestsellers[\"Reviews\"], fill=True, color=\"r\")\n",
        "sns.kdeplot(nonfiction_bestsellers[\"Reviews\"], fill=True, color=\"b\")\n",
        "plt.legend([\"Fiction\", \"Non Fiction\"])\n",
        "plt.xlabel(\"User Rating\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.show()"
      ],
      "id": "4d7631b6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calcular el coeficiente de asimetría\n",
        "skewness = stats.skew(bestsellers[\"Reviews\"])\n",
        "print(\"Coeficiente de asimetría:\", skewness)\n",
        "\n",
        "if skewness > 0:\n",
        "    print(\"La distribución está positivamente sesgada.\")\n",
        "elif skewness < 0:\n",
        "    print(\"La distribución está negativamente sesgada.\")\n",
        "else:\n",
        "    print(\"La distribución es simétrica.\")"
      ],
      "id": "56bd74af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Número de observaciones para cada grupo:\n"
      ],
      "id": "7ded5f73"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bestsellers[\"Genre\"].value_counts()"
      ],
      "id": "c7a0b0ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realizamos un test de normalidad para cada grupo:\n"
      ],
      "id": "2649cb7d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from scipy import stats\n",
        "\n",
        "\n",
        "def shapiro_test(data, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Realiza la prueba de Shapiro-Wilk para verificar la normalidad de los datos.\n",
        "\n",
        "    Parameters:\n",
        "    data (array-like): Los datos a analizar.\n",
        "    alpha (float): Nivel de significancia.\n",
        "\n",
        "    Returns:\n",
        "    str: El resultado de la prueba.\n",
        "    \"\"\"\n",
        "    statistic, p_value = stats.shapiro(data)\n",
        "\n",
        "    if p_value < alpha:\n",
        "        return (\n",
        "            \"Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\"\n",
        "        )\n",
        "    else:\n",
        "        return \"Fallamos al rechazar la hipótesis nula. Los datos pueden considerarse normalmente distribuidos.\"\n",
        "\n",
        "\n",
        "result_fiction = shapiro_test(fiction_bestsellers[\"Reviews\"])\n",
        "result_nonfiction = shapiro_test(nonfiction_bestsellers[\"Reviews\"])\n",
        "\n",
        "print(\"Para bestsellers de ficción:\", result_fiction)\n",
        "print(\"Para bestsellers de no ficción:\", result_nonfiction)"
      ],
      "id": "da177bef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estudiemos la relación entre las varianzas de cada grupo.\n"
      ],
      "id": "08a59e06"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# varianza de los grupos\n",
        "bestsellers.groupby([\"Genre\"])[\"Reviews\"].var()"
      ],
      "id": "ec8ce340",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Realiza el Test de Levene\n",
        "statistic, p_value = stats.levene(\n",
        "    fiction_bestsellers[\"User Rating\"], nonfiction_bestsellers[\"User Rating\"]\n",
        ")\n",
        "\n",
        "# Nivel de significancia\n",
        "alpha = 0.05\n",
        "\n",
        "# Comprueba la significancia\n",
        "if p_value < alpha:\n",
        "    print(\"Rechazamos la hipótesis nula. Las varianzas no son similares\")\n",
        "else:\n",
        "    print(\"Fallamos al rechazar la hipótesis nula. Las varianzas son similares\")"
      ],
      "id": "e5ee4374",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Seleccionamos la hipotesis y el nivel de significancia\n",
        "\n",
        "H0: El número de Reviews medio de los libros de ficción es igual que el de los libros de no ficción\n",
        "\n",
        "Ha: El número de Reviews medio de los libros de ficción es diferente que el de los libros de no ficción\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "### 2. Identificamos el tipo de test\n",
        "\n",
        "Deseamos comparar las medias de dos grupos de nuestra Sample. Por lo que un 2-Sample t-Test parece lo adecuado. Lo primero es ver si se cumplen los requisitos del test.\n",
        "\n",
        "#### 2.1 Requisitos del test\n",
        "[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\n",
        "Page: 48\n",
        "Section: 2-Sample t-Tests]\n",
        "- Tenemos un Sample representativo de la población? Si.\n",
        "- Los datos son continuos? Si.\n",
        "- Las muestras siguen una distribución normal o hay más de 15 observaciones\n",
        "  - No, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema del límite central podemos renunciar al supuesto de normalidad.\n",
        "- Los grupos son independientes? Si.\n",
        "- Las varianzas son iguales (o al menos similares)?\n",
        "  - No.\n",
        "\n",
        "\n",
        "Las varianzas no son similares y su relación es de más del doble. Vamos a reliazar un test tipo **Welch's t-test**.\n",
        "\n",
        "Para realizar el test vamos a usar [scipy.stats.ttest_ind](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html).\n",
        "Para realizar este test, es necesario definir el parametro *equal_varbool* como *False*.\n"
      ],
      "id": "9229a6af"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Realiza el test t de Welch (equal_var=False)\n",
        "statistic, p_value = stats.ttest_ind(\n",
        "    nonfiction_bestsellers[\"Reviews\"], fiction_bestsellers[\"Reviews\"], equal_var=False\n",
        ")\n",
        "\n",
        "# Imprime los resultados\n",
        "print(\"Valor p:\", p_value)\n",
        "\n",
        "# Comprueba la significancia\n",
        "alpha = 0.05  # Nivel de significancia\n",
        "if p_value < alpha:\n",
        "    print(\n",
        "        \"Rechazamos la hipótesis nula: Hay diferencias significativas entre los grupos.\"\n",
        "    )\n",
        "else:\n",
        "    print(\n",
        "        \"No podemos rechazar la hipótesis nula: No hay diferencias significativas entre los grupos.\"\n",
        "    )"
      ],
      "id": "e1da9144",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los libros del género de ficción obtienen más Reviews que los libros de no ficción.\n",
        "\n",
        "## ¿Los géneros difieren en términos de Price?\n",
        "\n",
        "Representamos gráficamente los datos.\n"
      ],
      "id": "1ab3468e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.kdeplot(fiction_bestsellers[\"Price\"], fill=True, color=\"r\")\n",
        "sns.kdeplot(nonfiction_bestsellers[\"Price\"], fill=True, color=\"b\")\n",
        "plt.legend([\"Fiction\", \"Non Fiction\"])\n",
        "plt.xlabel(\"User Rating\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.show()"
      ],
      "id": "a26fb089",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calcular el coeficiente de asimetría\n",
        "skewness = stats.skew(bestsellers[\"Price\"])\n",
        "print(\"Coeficiente de asimetría:\", skewness)\n",
        "\n",
        "if skewness > 0:\n",
        "    print(\"La distribución está positivamente sesgada.\")\n",
        "elif skewness < 0:\n",
        "    print(\"La distribución está negativamente sesgada.\")\n",
        "else:\n",
        "    print(\"La distribución es simétrica.\")"
      ],
      "id": "4a645ff6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realizamos un test de normalidad para cada grupo:\n"
      ],
      "id": "ab4845a0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from scipy import stats\n",
        "\n",
        "\n",
        "def shapiro_test(data, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Realiza la prueba de Shapiro-Wilk para verificar la normalidad de los datos.\n",
        "\n",
        "    Parameters:\n",
        "    data (array-like): Los datos a analizar.\n",
        "    alpha (float): Nivel de significancia.\n",
        "\n",
        "    Returns:\n",
        "    str: El resultado de la prueba.\n",
        "    \"\"\"\n",
        "    statistic, p_value = stats.shapiro(data)\n",
        "\n",
        "    if p_value < alpha:\n",
        "        return (\n",
        "            \"Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\"\n",
        "        )\n",
        "    else:\n",
        "        return \"Fallamos al rechazar la hipótesis nula. Los datos pueden considerarse normalmente distribuidos.\"\n",
        "\n",
        "\n",
        "result_fiction = shapiro_test(fiction_bestsellers[\"Price\"])\n",
        "result_nonfiction = shapiro_test(nonfiction_bestsellers[\"Price\"])\n",
        "\n",
        "print(\"Para bestsellers de ficción:\", result_fiction)\n",
        "print(\"Para bestsellers de no ficción:\", result_nonfiction)"
      ],
      "id": "adae3225",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estudiemos la relación entre las varianzas de cada grupo.\n"
      ],
      "id": "7bd35c53"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Realiza el Test de Levene\n",
        "statistic, p_value = stats.levene(\n",
        "    fiction_bestsellers[\"Price\"], nonfiction_bestsellers[\"Price\"]\n",
        ")\n",
        "\n",
        "# Nivel de significancia\n",
        "alpha = 0.05\n",
        "\n",
        "# Comprueba la significancia\n",
        "if p_value < alpha:\n",
        "    print(\"Rechazamos la hipótesis nula. Las varianzas no son similares\")\n",
        "else:\n",
        "    print(\"Fallamos al rechazar la hipótesis nula. Las varianzas son similares\")"
      ],
      "id": "fc0279d2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# varianza de los grupos\n",
        "bestsellers.groupby([\"Genre\"])[\"Price\"].var()"
      ],
      "id": "461cf1d6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Seleccionamos la hipotesis y el nivel de significancia\n",
        "\n",
        "H0: El precio medio de los libros de ficción es igual que el de los libros de no ficción\n",
        "\n",
        "Ha: El precio medio de los libros de ficción es diferente que el de los libros de no ficción\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "### 2. Identificamos el tipo de test\n",
        "\n",
        "Deseamos comparar las medias de dos grupos de nuestra Sample. Por lo que un 2-Sample t-Test parece lo adecuado. Lo primero es ver si se cumplen los requisitos del test.\n",
        "\n",
        "#### 2.1 Requisitos del test\n",
        "[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\n",
        "Page: 48\n",
        "Section: 2-Sample t-Tests]\n",
        "- Tenemos un Sample representativo de la población? Si.\n",
        "- Los datos son continuos? Si.\n",
        "- Las muestras siguen una distribución normal o hay más de 15 observaciones\n",
        "  - No, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema del límite central podemos renunciar al supuesto de normalidad.\n",
        "- Los grupos son independientes? Si.\n",
        "- Las varianzas son iguales (o al menos similares)? Si.\n",
        "\n",
        "Se cumplen los requisitos para realizar un **2-Sample t-Test**.\n",
        "\n",
        "Para realizar el test vamos a usar [scipy.stats.ttest_ind](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html).\n"
      ],
      "id": "7b888ddb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Realiza el test t\n",
        "statistic, p_value = stats.ttest_ind(\n",
        "    nonfiction_bestsellers[\"Price\"], fiction_bestsellers[\"Price\"]\n",
        ")\n",
        "\n",
        "# Imprime los resultados\n",
        "print(\"Valor p:\", p_value)\n",
        "\n",
        "# Comprueba la significancia\n",
        "alpha = 0.05  # Nivel de significancia\n",
        "if p_value < alpha:\n",
        "    print(\n",
        "        \"Rechazamos la hipótesis nula: Hay diferencias significativas entre los grupos.\"\n",
        "    )\n",
        "else:\n",
        "    print(\n",
        "        \"No podemos rechazar la hipótesis nula: No hay diferencias significativas entre los grupos.\"\n",
        "    )"
      ],
      "id": "85243635",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El precio no es dependiente del género.\n"
      ],
      "id": "c3e14d49"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}