[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Blog",
    "section": "",
    "text": "Test de Hipótesis: explorando correlaciones en datos de seguros de salud\n\n\nSe utiliza como base el libro de Jim Fros: 'Hypothesis Testing: An Intuitive Guide for Making Data Driven Decisions'. Este análisis se enfoca en descubrir y entender las correlaciones subyacentes en los datos de seguros de salud, aplicando métodos de prueba de hipótesis para revelar tendencias y patrones significativos.\n\n\n\n`2023-11-14`{=html}\n\n\n\n\n\n\n\n\n\nTest de Hipótesis: Análisis de los 50 libros más vendidos en amazon (2009 - 2019)\n\n\nEste análisis profundiza en cómo el género literario influye en la valoración de los usuarios, el número de reseñas y el precio de los bestsellers en Amazon.\n\n\n\n`2023-10-16`{=html}\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html",
    "href": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html",
    "title": "Test de Hipótesis: Análisis de los 50 libros más vendidos en amazon (2009 - 2019)",
    "section": "",
    "text": "From Kaggle: Amazon Top 50 Bestselling Books 2009 - 2019\n\n\nDataset sobre los 50 libros más vendidos de Amazon de 2009 a 2019. Contiene 550 libros, los datos se han clasificado en ficción y no-ficción utilizando Goodreads.\n\n\n\nVamos a responder a las siguientes preguntas con validez estadística:\n\n¿Los géneros difieren en “User Rating”?\n¿Los géneros difieren en número de “Reviews”?\n¿Los géneros difieren en términos de “Price”?\n\n\n\n\n\n\n\nMatemáticas y código: en Inglés\n\n\n\n\n\nAunque el texto principal está en español, los términos matemáticos, los títulos de secciones y el código están en inglés.\nEsta práctica sigue el estándar internacional y ayuda a familiarizarse con el lenguaje técnico más utilizado en el campo de la ciencia de datos."
  },
  {
    "objectID": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#a.-entendimiento-del-negocio",
    "href": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#a.-entendimiento-del-negocio",
    "title": "Test de Hipótesis: Análisis de los 50 libros más vendidos en amazon (2009 - 2019)",
    "section": "",
    "text": "From Kaggle: Amazon Top 50 Bestselling Books 2009 - 2019\n\n\nDataset sobre los 50 libros más vendidos de Amazon de 2009 a 2019. Contiene 550 libros, los datos se han clasificado en ficción y no-ficción utilizando Goodreads.\n\n\n\nVamos a responder a las siguientes preguntas con validez estadística:\n\n¿Los géneros difieren en “User Rating”?\n¿Los géneros difieren en número de “Reviews”?\n¿Los géneros difieren en términos de “Price”?\n\n\n\n\n\n\n\nMatemáticas y código: en Inglés\n\n\n\n\n\nAunque el texto principal está en español, los términos matemáticos, los títulos de secciones y el código están en inglés.\nEsta práctica sigue el estándar internacional y ayuda a familiarizarse con el lenguaje técnico más utilizado en el campo de la ciencia de datos."
  },
  {
    "objectID": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#b.-descripción-de-datos",
    "href": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#b.-descripción-de-datos",
    "title": "Test de Hipótesis: Análisis de los 50 libros más vendidos en amazon (2009 - 2019)",
    "section": "1b. Descripción de datos",
    "text": "1b. Descripción de datos\nPara empezar, importamos las librerías que vamos a utilizar:\n\nPandas: Pandas es una biblioteca esencial en la ciencia de datos que proporciona estructuras de datos flexibles y eficientes, como DataFrames, para el análisis y manipulación de datos tabulares. Es ampliamente utilizada para limpiar, transformar y analizar datos, lo que la convierte en una herramienta fundamental para la preparación de datos en proyectos de ciencia de datos.\nScipy: Scipy es una biblioteca que se construye sobre NumPy y ofrece una amplia variedad de módulos y funciones especializadas para aplicaciones científicas y matemáticas. Incluye herramientas para estadísticas, optimización, álgebra lineal y procesamiento de señales, lo que la hace esencial en la investigación y el análisis de datos en ciencia de datos.\nFuzzywuzzy: Fuzzywuzzy es una biblioteca que se utiliza en la ciencia de datos para comparar cadenas de texto difusas o parcialmente coincidentes. Es útil en la limpieza y normalización de datos de texto, así como en la identificación de similitudes entre strings, lo que es valioso en tareas como la duplicación de registros o la coincidencia de nombres en bases de datos.\nPlotly Express: Plotly Express es una biblioteca de visualización de datos que simplifica la creación de gráficos interactivos y visuales. Es especialmente útil en la exploración de datos y la comunicación de resultados en ciencia de datos, permitiendo a los científicos de datos crear visualizaciones informativas y atractivas con facilidad.\n\n\n\nCode\n# Import libraries\nimport pandas as pd\nfrom scipy import stats\nfrom fuzzywuzzy import fuzz\n\n# Import plotly and customize\nimport plotly.io as pio\nimport plotly.express as px\n\n# Set a global template, e.g. \"plotly_dark\"\n# Customize the color scheme of the chosen template, e.g. \"Set2\"\npio.templates.default = \"plotly\"\npio.templates[\"plotly\"].layout.colorway = px.colors.qualitative.Set2\n\n\nCargamos el dataset y describimos brevemente sus características.\n\ndf = pd.read_csv(\"bestsellers with categories.csv\")\ndf.head(5)\n\n\n\n\n\n\n\n\nName\nAuthor\nUser Rating\nReviews\nPrice\nYear\nGenre\n\n\n\n\n0\n10-Day Green Smoothie Cleanse\nJJ Smith\n4.7\n17350\n8\n2016\nNon Fiction\n\n\n1\n11/22/63: A Novel\nStephen King\n4.6\n2052\n22\n2011\nFiction\n\n\n2\n12 Rules for Life: An Antidote to Chaos\nJordan B. Peterson\n4.7\n18979\n15\n2018\nNon Fiction\n\n\n3\n1984 (Signet Classics)\nGeorge Orwell\n4.7\n21424\n6\n2017\nFiction\n\n\n4\n5,000 Awesome Facts (About Everything!) (Natio...\nNational Geographic Kids\n4.8\n7665\n12\n2019\nNon Fiction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCampo\nTipo de Dato\nDescripción\nEjemplo\n\n\n\n\nName\nTexto\nTítulo del libro.\n11/22/63: A Novel\n\n\nAuthor\nTexto\nAutor del libro.\nStephen King\n\n\nUser Rating\nNumérico entre 0 y 5 (con un decimal)\nCalificación promedio otorgada por usuarios.\n4.6\n\n\nReviews\nNumérico (entero)\nCantidad de reseñas del libro.\n2052\n\n\nPrice\nNumérico (entero)\nPrecio de venta del libro.\n22\n\n\nYear\nAño (número entero)\nAño de inclusión en la lista de más vendidos.\n2011\n\n\nGenre\nCategórico\nGénero del libro, ficción o no ficción.\nFicción\n\n\n\nEstos son los tipos de datos que se identifican en primer momento. Como veremos más adelante, estas designaciones pueden ser problemáticas según los valores que contenga el dataset y los insights que queramos obtener."
  },
  {
    "objectID": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#a.-preparación-de-los-datos",
    "href": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#a.-preparación-de-los-datos",
    "title": "Test de Hipótesis: Análisis de los 50 libros más vendidos en amazon (2009 - 2019)",
    "section": "2a. Preparación de los datos",
    "text": "2a. Preparación de los datos\n\n2a.1 Typecasting\nComprobamos el tipo de datos de las columnas y los modificamos conforme nuestra descripción inicial.\n\ndf.dtypes\n\nName            object\nAuthor          object\nUser Rating    float64\nReviews          int64\nPrice            int64\nYear             int64\nGenre           object\ndtype: object\n\n\n\ncategorical_columns = [\"Genre\", \"Name\", \"Author\"]\ndf[categorical_columns] = df[categorical_columns].astype(\"category\")\n\n\ndf.dtypes\n\nName           category\nAuthor         category\nUser Rating     float64\nReviews           int64\nPrice             int64\nYear              int64\nGenre          category\ndtype: object\n\n\n\n\n2a.2 Manejo de duplicados\n\nSimpler approach\n¿Cuantas filas son exactamente iguales?\n\ndf.duplicated().sum()\n\n0\n\n\nEs normal no encontrar duplicados en este caso, ya que hay libros que se repiten, pero es imposible que coincidan en “Year”. No es un error en sí mismo. Sin embargo, hay un problema. Las “Reviews” deberían ser las que el libro tenía en el año en el que fue uno de los más vendidos. En lugar de eso, son las del último año. Esto podría deberse a que el autor del dataset no tuvo acceso al historial de las reseñas.\n\n\nRepeated Bestsellers\n\ndf[df.duplicated(\"Name\")]\n\n\n\n\n\n\n\n\nName\nAuthor\nUser Rating\nReviews\nPrice\nYear\nGenre\n\n\n\n\n10\nA Man Called Ove: A Novel\nFredrik Backman\n4.6\n23848\n8\n2017\nFiction\n\n\n21\nAll the Light We Cannot See\nAnthony Doerr\n4.6\n36348\n14\n2015\nFiction\n\n\n33\nBecoming\nMichelle Obama\n4.8\n61133\n11\n2019\nNon Fiction\n\n\n36\nBetween the World and Me\nTa-Nehisi Coates\n4.7\n10070\n13\n2016\nNon Fiction\n\n\n41\nBrown Bear, Brown Bear, What Do You See?\nBill Martin Jr.\n4.9\n14344\n5\n2019\nFiction\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n543\nWonder\nR. J. Palacio\n4.8\n21625\n9\n2016\nFiction\n\n\n544\nWonder\nR. J. Palacio\n4.8\n21625\n9\n2017\nFiction\n\n\n547\nYou Are a Badass: How to Stop Doubting Your Gr...\nJen Sincero\n4.7\n14331\n8\n2017\nNon Fiction\n\n\n548\nYou Are a Badass: How to Stop Doubting Your Gr...\nJen Sincero\n4.7\n14331\n8\n2018\nNon Fiction\n\n\n549\nYou Are a Badass: How to Stop Doubting Your Gr...\nJen Sincero\n4.7\n14331\n8\n2019\nNon Fiction\n\n\n\n\n199 rows × 7 columns\n\n\n\nHay 199 libros que han sido bestsellers durante más de un año. Es importante tener en cuenta esto para el análisis. Vamos a utilizar únicamente la muestra más reciente de cada libro.\n\nbestsellers = df.drop_duplicates(subset=\"Name\", keep=\"last\")\n\n\n\nChecking for authors or titles with different spellings\nComprobamos si hay autores o títulos iguales pero escritos diferente.\n\n# Function to find similar author names\ndef find_similar(df, column):\n    authors = df[column].unique()\n    duplicates = []\n\n    for i, author1 in enumerate(authors):\n        for author2 in authors[i + 1 :]:\n            ratio = fuzz.ratio(author1, author2)\n            if ratio &gt; 90:  # You can adjust this threshold according to your criteria\n                duplicates.append((author1, author2))\n\n    return duplicates\n\n\n# Find similar author names\nduplicates = find_similar(bestsellers, \"Author\")\n\nprint(\"Author names that refer to the same author but are written differently:\")\nfor dup in duplicates:\n    print(dup)\n\n# Find similar title names\nduplicates = find_similar(bestsellers, \"Name\")\n\nprint(\"Title names that refer to the same title but are written differently:\")\nfor dup in duplicates:\n    print(dup)\n\nAuthor names that refer to the same author but are written differently:\n('George R. R. Martin', 'George R.R. Martin')\n('J.K. Rowling', 'J. K. Rowling')\nTitle names that refer to the same title but are written differently:\n('The 5 Love Languages: The Secret to Love That Lasts', 'The 5 Love Languages: The Secret to Love that Lasts')\n('The Girl Who Played with Fire (Millennium Series)', 'The Girl Who Played with Fire (Millennium)')\n\n\n\n# Replace the names of the Authors with the correct ones\nbestsellers = bestsellers.replace(\"George R. R. Martin\", \"George R.R. Martin\")\nbestsellers = bestsellers.replace(\"J. K. Rowling\", \"J.K. Rowling\")\n\n# Replace the names of the Authors with the correct ones\nbestsellers = bestsellers.replace(\n    \"The 5 Love Languages: The Secret to Love That Lasts\",\n    \"The 5 Love Languages: The Secret to Love that Lasts\",\n)\nbestsellers = bestsellers.replace(\n    \"The Girl Who Played with Fire (Millennium Series)\",\n    \"The Girl Who Played with Fire (Millennium)\",\n)\n\n\nbestsellers\n\n\n\n\n\n\n\n\nName\nAuthor\nUser Rating\nReviews\nPrice\nYear\nGenre\n\n\n\n\n0\n10-Day Green Smoothie Cleanse\nJJ Smith\n4.7\n17350\n8\n2016\nNon Fiction\n\n\n1\n11/22/63: A Novel\nStephen King\n4.6\n2052\n22\n2011\nFiction\n\n\n2\n12 Rules for Life: An Antidote to Chaos\nJordan B. Peterson\n4.7\n18979\n15\n2018\nNon Fiction\n\n\n3\n1984 (Signet Classics)\nGeorge Orwell\n4.7\n21424\n6\n2017\nFiction\n\n\n4\n5,000 Awesome Facts (About Everything!) (Natio...\nNational Geographic Kids\n4.8\n7665\n12\n2019\nNon Fiction\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n538\nWinter of the World: Book Two of the Century T...\nKen Follett\n4.5\n10760\n15\n2012\nFiction\n\n\n539\nWomen Food and God: An Unexpected Path to Almo...\nGeneen Roth\n4.2\n1302\n11\n2010\nNon Fiction\n\n\n544\nWonder\nR. J. Palacio\n4.8\n21625\n9\n2017\nFiction\n\n\n545\nWrecking Ball (Diary of a Wimpy Kid Book 14)\nJeff Kinney\n4.9\n9413\n8\n2019\nFiction\n\n\n549\nYou Are a Badass: How to Stop Doubting Your Gr...\nJen Sincero\n4.7\n14331\n8\n2019\nNon Fiction\n\n\n\n\n351 rows × 7 columns\n\n\n\n\n\nIdeas destacadas\n\nHemos corregido las variaciones ortográficas de los títulos y autores.\nHemos seleccionado las muestras más recientes de cada libro.\n\nCon esto, se ha reducido el tamaño del dataset de 550 a 351 muestras.\n\n\n\n2a.3 Análisis de valores atípicos\n\nselected_columns = [\"Reviews\", \"Price\"]\n\nfor column in selected_columns:\n    fig = px.box(df, x=column, title=f\"Boxplot of {column}\")\n    fig.update_layout(title_x=0.5)\n    fig.show()\n\n\n                                                \n\n\n\n                                                \n\n\n\nIdeas destacadas\nSe pueden hacer tres cosas con los outliers, siguiendo la mnemotecnia 3R: rectificar, retener o remover. En este caso, podemos estar ante valores atípicos genuinos, por tanto vamos a retenerlos por el momento.\n\n\n\n2a.4 Variables con varianza cercana a cero\nSi la variance es cero, la variable no aporta información para el análisis estadístico o el modelado, por lo tanto, puede ser eliminada.\nSi la variance es casi cero, también es una variable candidata a ser eliminada, ya que aporta poca información y puede generar ruido en el análisis.\nEs importante tener en cuenta que el umbral para considerar una variable como “Near Zero Variance” puede variar según el contexto y el problema específico que se esté abordando.\n\nselected_columns = [\"User Rating\", \"Reviews\", \"Price\"]\n\n# Calculate the variance of each column\nvariances = bestsellers[selected_columns].var()\n\n# Define a threshold for variance\nthreshold = 0.1\n\n# Identify columns with near-zero or very small variance\nzero_variance_cols = variances[variances &lt;= threshold].index\n\nprint(\"Columns with Zero & Near Zero Variance:\")\nprint(zero_variance_cols)\n\nColumns with Zero & Near Zero Variance:\nIndex(['User Rating'], dtype='object')\n\n\nLa variable “User Rating” parece estar por debajo del umbral que hemos escogido arbitrariamente. Vamos a representarla gráficamente para comprender mejor la situación.\n\ncolumn = \"User Rating\"\nfig = px.violin(df, x=column, title=f\"Violin plot of {column}\", points=\"all\")\nfig.update_layout(title_x=0.5, xaxis=dict(range=[0, 5.5]))\nfig.show()\n\n\n                                                \n\n\n\nIdeas destacadas\nAl trabajar con un dataset de bestsellers, la mayoría de los “User Rating” están entre 4 y 5 estrellas, mientras que inicialmente se esperaba que las muestras estuvieran repartidas entre 0 y 5.\nEs importante tener esto presente en posteriores análisis, ya que casi podría considerarse una variable categórica en lugar de continua.\n\n\n\n2a.5 Valores ausentes o faltantes\n\nbestsellers.isnull().sum()\n\nName           0\nAuthor         0\nUser Rating    0\nReviews        0\nPrice          0\nYear           0\nGenre          0\ndtype: int64\n\n\n\nIdeas destacadas\n\nNo hay missing values"
  },
  {
    "objectID": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#pruebas-de-hipótesis",
    "href": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#pruebas-de-hipótesis",
    "title": "Test de Hipótesis: Análisis de los 50 libros más vendidos en amazon (2009 - 2019)",
    "section": "4. Pruebas de hipótesis",
    "text": "4. Pruebas de hipótesis\nVamos a responder a las siguientes preguntas con validez estadística:\n\n¿Los géneros difieren en “User Rating”?\n¿Los géneros difieren en número de “Reviews”?\n¿Los géneros difieren en términos de “Price”?\n\n\n4.1 ¿Los géneros difieren en “User Rating”?\nPrimero hagamos una exploración visual.\n\nfig = px.violin(\n    bestsellers,\n    x=\"User Rating\",\n    color=\"Genre\",\n    box=True,\n    points=\"outliers\",\n)\n\nfig.update_layout(\n    title_text=\"User Rating violin plot by Genre\",\n)\n\nfig.show()\n\n\n                                                \n\n\nParece que existen diferencias. ¿Pero son estadísticamente significativas? Vamos a comprobarlo con un test de hipótesis.\n\n1. Seleccionamos la hipótesis y el nivel de significancia\nH0: El “User Rating” de los libros de ficción es igual que el de los libros de no ficción.\nHa: El “User Rating” de los libros de ficción es diferente al de los libros de no ficción.\nalpha = 0.05\n\n\n2. Identificamos el tipo de test\nDeseamos comparar las medias de dos grupos de nuestra sample. Por lo tanto, un 2-Sample t-Test parece ser adecuado. Lo primero es verificar si se cumplen los requisitos del test.\n\n2.1 Requisitos del test\n\nTenemos una sample representativa de la population.\nLos datos son continuos.\nLas muestras siguen una distribución normal o hay más de 15 observaciones.\nLos grupos son independientes.\nLas varianzas son iguales (o al menos similares).\n\nExaminemos nuestra sample para ver si podemos aplicar el test.\n\n\n\n\n\n\nLibro de refencia\n\n\n\n\n\nBook: Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 48\nSection: 2-Sample t-Tests\n\n\n\nNúmero de observaciones para cada grupo:\n\nbestsellers[\"Genre\"].value_counts()\n\nGenre\nNon Fiction    191\nFiction        160\nName: count, dtype: int64\n\n\nRealizamos un test de normalidad para cada grupo:\n\nfiction_bestsellers = bestsellers[bestsellers[\"Genre\"] == \"Fiction\"]\nnonfiction_bestsellers = bestsellers[bestsellers[\"Genre\"] == \"Non Fiction\"]\n\n\ndef shapiro_test(data, alpha=0.05):\n    \"\"\"\n    Perform the Shapiro-Wilk test to check the normality of the data.\n\n    Parameters:\n    data (array-like): The data to analyze.\n    alpha (float): Significance level.\n\n    Returns:\n    str: The test result.\n    \"\"\"\n    statistic, p_value = stats.shapiro(data)\n\n    if p_value &lt; alpha:\n        return \"We reject the null hypothesis. The data does not follow a normal distribution.\"\n    else:\n        return \"We fail to reject the null hypothesis. The data can be considered normally distributed.\"\n\n\nresult_fiction = shapiro_test(fiction_bestsellers[\"User Rating\"])\nresult_nonfiction = shapiro_test(nonfiction_bestsellers[\"User Rating\"])\n\nprint(\"For fiction bestsellers:\", result_fiction)\nprint(\"For non-fiction bestsellers:\", result_nonfiction)\n\nFor fiction bestsellers: We reject the null hypothesis. The data does not follow a normal distribution.\nFor non-fiction bestsellers: We reject the null hypothesis. The data does not follow a normal distribution.\n\n\nEstudiemos la relación entre las varianzas de cada grupo.\n\n# Perform the Levene's Test\nstatistic, p_value = stats.levene(\n    fiction_bestsellers[\"User Rating\"], nonfiction_bestsellers[\"User Rating\"]\n)\n\n# Significance level\nalpha = 0.05\n\n# Check for significance\nif p_value &lt; alpha:\n    print(\"We reject the null hypothesis. The variances are not similar.\")\nelse:\n    print(\"We fail to reject the null hypothesis. The variances are similar.\")\n\nWe reject the null hypothesis. The variances are not similar.\n\n\nVolvamos sobre los requisitos del test:\n\n¿Tenemos una sample representativa de la population? Suponemos que sí.\n¿Los datos son continuos?\n\nEn este contexto, los “User Rating” que van de 0 a 5 con un único decimal pueden considerarse como datos continuos. Sin embargo, observando las gráficas, vemos que la mayoría de los valores se encuentran en un intervalo muy pequeño (mayores a 4.0). Esto dificulta considerarlos como continuos.\n\n¿Las muestras siguen una distribución normal o hay más de 15 observaciones?\n\nNo, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema central del límite podemos renunciar al supuesto de normalidad.\n\n¿Los grupos son independientes? Sí.\n¿Las varianzas son iguales (o al menos similares)?\n\nNo.\n\n\nDada la falta de continuidad en los datos, vamos a realizar un test no paramétrico Mann-Whitney.\nPara realizar el test utilizaremos scipy.stats.mannwhitneyu\n\n\n\n\n\n\nLibro de refencia\n\n\n\n\n\nBook:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 341\nSection: Analyzing Likert Scale Data\n\n\n\n\n# Perform the Mann-Whitney U test\nstatistic, p_value = stats.mannwhitneyu(\n    nonfiction_bestsellers[\"User Rating\"], fiction_bestsellers[\"User Rating\"]\n)\n\n# Print the results\nprint(\"p-value:\", p_value)\n\n# Check for significance\nalpha = 0.05  # Significance level\nif p_value &lt; alpha:\n    print(\n        \"We reject the null hypothesis. There are significant differences between the groups.\"\n    )\nelse:\n    print(\n        \"We fail to reject the null hypothesis. There are no significant differences between the groups.\"\n    )\n\np-value: 0.019226481868505015\nWe reject the null hypothesis. There are significant differences between the groups.\n\n\n\n\n\nIdeas destacadas\nPodemos afirmar que hay diferencias significativas en términos de “User Rating” entre los libros de ficción y los de no ficción.\n\n\n\n4.2 ¿Los géneros difieren en número de “Reviews”?\nPrimero hagamos una exploración visual.\n\nfig = px.violin(\n    bestsellers,\n    x=\"Reviews\",\n    color=\"Genre\",\n    box=True,\n    points=\"outliers\",\n)\n\nfig.update_layout(\n    title_text=\"Reviews violin plot by Genre\",\n)\n\nfig.show()\n\n\n                                                \n\n\nParece que existen difencias. ¿Pero son estadisticamente significativas? Vamos a comprobarlo con un test de hipótesis.\n\n1. Seleccionamos la hipotesis y el nivel de significancia\nH0: El número de ‘Reviews’ medio de los libros de ficción es igual que el de los libros de no ficción\nHa: El número de ‘Reviews’ medio de los libros de ficción es diferente que el de los libros de no ficción\nalpha = 0.05\n\n\n2. Identificamos el tipo de test\nDeseamos comparar las medias de dos grupos de nuestra sample. Por lo tanto, un 2-Sample t-Test parece ser adecuado. Lo primero es verificar si se cumplen los requisitos del test.\n\n2.1 Requisitos del test\n\nTenemos una sample representativa de la population.\nLos datos son continuos.\nLas muestras siguen una distribución normal o hay más de 15 observaciones.\nLos grupos son independientes.\nLas varianzas son iguales (o al menos similares).\n\nExaminemos nuestra sample para ver si podemos aplicar el test.\n\n\n\n\n\n\nLibro de refencia\n\n\n\n\n\nBook: Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 48\nSection: 2-Sample t-Tests\n\n\n\nNúmero de observaciones para cada grupo:\n\nbestsellers[\"Genre\"].value_counts()\n\nGenre\nNon Fiction    191\nFiction        160\nName: count, dtype: int64\n\n\nRealizamos un test de normalidad para cada grupo:\n\nresult_fiction = shapiro_test(fiction_bestsellers[\"Reviews\"])\nresult_nonfiction = shapiro_test(nonfiction_bestsellers[\"Reviews\"])\n\nprint(\"Para bestsellers de ficción:\", result_fiction)\nprint(\"Para bestsellers de no ficción:\", result_nonfiction)\n\nPara bestsellers de ficción: We reject the null hypothesis. The data does not follow a normal distribution.\nPara bestsellers de no ficción: We reject the null hypothesis. The data does not follow a normal distribution.\n\n\nEstudiemos la relación entre las varianzas de cada grupo.\n\n# Perform the Levene's Test\nstatistic, p_value = stats.levene(\n    fiction_bestsellers[\"User Rating\"], nonfiction_bestsellers[\"User Rating\"]\n)\n\n# Significance level\nalpha = 0.05\n\n# Check for significance\nif p_value &lt; alpha:\n    print(\"We reject the null hypothesis. The variances are not similar.\")\nelse:\n    print(\"We fail to reject the null hypothesis. The variances are similar.\")\n\nWe reject the null hypothesis. The variances are not similar.\n\n\nVolvamos sobre los requisitos del test:\n\n¿Tenemos una sample representativa de la population? Suponemos que sí.\n¿Los datos son continuos? Sí.\n¿Las muestras siguen una distribución normal o hay más de 15 observaciones?\n\nNo, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema central del límite podemos renunciar al supuesto de normalidad.\n\n¿Los grupos son independientes? Sí.\n¿Las varianzas son iguales (o al menos similares)?\n\nNo, las varianzas no son similares.\n\n\nLas varianzas no son similares. Vamos a realizar un test tipo Welch’s t-test.\nPara realizar el test utilizaremos scipy.stats.ttest_ind. Es necesario definir el parámetro equal_varbool como False.\n\n# Perform the Welch's t-test (equal_var=False)\nstatistic, p_value = stats.ttest_ind(\n    nonfiction_bestsellers[\"Reviews\"], fiction_bestsellers[\"Reviews\"], equal_var=False\n)\n\n# Print the results\nprint(\"p-value:\", p_value)\n\n# Check for significance\nalpha = 0.05  # Significance level\nif p_value &lt; alpha:\n    print(\n        \"We reject the null hypothesis: There are significant differences between the groups.\"\n    )\nelse:\n    print(\n        \"We cannot reject the null hypothesis: There are no significant differences between the groups.\"\n    )\n\np-value: 4.3970747273288255e-07\nWe reject the null hypothesis: There are significant differences between the groups.\n\n\n\n\n\nIdeas destacadas\nPodemos afirmar que hay diferencias significativas en términos de número de “Reviews” entre los libros de ficción y los de no ficción. Los libros del género de ficción obtienen, en media, más Reviews que los libros de no ficción.\n\n\n\n4.3 ¿Los géneros difieren en términos de “Price”?\nPrimero hagamos una exploración visual.\n\nfig = px.violin(\n    bestsellers,\n    x=\"Price\",\n    color=\"Genre\",\n    box=True,\n    points=\"outliers\",\n)\n\nfig.update_layout(\n    title_text=\"Price violin plot by Genre\",\n)\n\nfig.show()\n\n\n                                                \n\n\nEn esta ocasión “Price” podría no variar en función del género. ¿Pero es estadísticamente significativo? Vamos a comprobarlo con un test de hipótesis.\n\n1. Seleccionamos la hipotesis y el nivel de significancia\nH0: El precio medio de los libros de ficción es igual que el de los libros de no ficción\nHa: El precio medio de los libros de ficción es diferente que el de los libros de no ficción\nalpha = 0.05\n\n\n2. Identificamos el tipo de test\nDeseamos comparar las medias de dos grupos de nuestra sample. Por lo tanto, un 2-Sample t-Test parece ser adecuado. Lo primero es verificar si se cumplen los requisitos del test.\n\n2.1 Requisitos del test\n\nTenemos una sample representativa de la population.\nLos datos son continuos.\nLas muestras siguen una distribución normal o hay más de 15 observaciones.\nLos grupos son independientes.\nLas varianzas son iguales (o al menos similares).\n\nExaminemos nuestra sample para ver si podemos aplicar el test.\n\n\n\n\n\n\nLibro de refencia\n\n\n\n\n\nBook: Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 48\nSection: 2-Sample t-Tests\n\n\n\nRealizamos un test de normalidad para cada grupo:\n\nresult_fiction = shapiro_test(fiction_bestsellers[\"Price\"])\nresult_nonfiction = shapiro_test(nonfiction_bestsellers[\"Price\"])\n\nprint(\"Para bestsellers de ficción:\", result_fiction)\nprint(\"Para bestsellers de no ficción:\", result_nonfiction)\n\nPara bestsellers de ficción: We reject the null hypothesis. The data does not follow a normal distribution.\nPara bestsellers de no ficción: We reject the null hypothesis. The data does not follow a normal distribution.\n\n\nEstudiemos la relación entre las varianzas de cada grupo.\n\n# Perform the Levene's Test\nstatistic, p_value = stats.levene(\n    fiction_bestsellers[\"Price\"], nonfiction_bestsellers[\"Price\"]\n)\n\n# Significance level\nalpha = 0.05\n\n# Check for significance\nif p_value &lt; alpha:\n    print(\"We reject the null hypothesis. The variances are not similar.\")\nelse:\n    print(\"We fail to reject the null hypothesis. The variances are similar.\")\n\nWe fail to reject the null hypothesis. The variances are similar.\n\n\nVolvamos sobre los requisitos del test:\n\n¿Tenemos una sample representativa de la population? Suponemos que sí.\n¿Los datos son continuos? Sí.\n¿Las muestras siguen una distribución normal o hay más de 15 observaciones?\n\nNo, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema central del límite podemos renunciar al supuesto de normalidad.\n\n¿Los grupos son independientes? Sí.\n¿Las varianzas son iguales (o al menos similares)? Sí.\n\nSe cumplen los requisitos para realizar un 2-Sample t-Test.\nPara realizar el test vamos a usar scipy.stats.ttest_ind.\n\n# Perform the t-test\nstatistic, p_value = stats.ttest_ind(\n    nonfiction_bestsellers[\"Price\"], fiction_bestsellers[\"Price\"]\n)\n\n# Print the results\nprint(\"p-value:\", p_value)\n\n# Check for significance\nalpha = 0.05  # Significance level\nif p_value &lt; alpha:\n    print(\n        \"We reject the null hypothesis: There are significant differences between the groups.\"\n    )\nelse:\n    print(\n        \"We cannot reject the null hypothesis: There are no significant differences between the groups.\"\n    )\n\np-value: 0.1398175523683507\nWe cannot reject the null hypothesis: There are no significant differences between the groups.\n\n\n\n\n\nIdeas destacadas\nNo encontramos diferencias en el precio en función del género del libro."
  },
  {
    "objectID": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#recapitulación-y-reflexiones",
    "href": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#recapitulación-y-reflexiones",
    "title": "Test de Hipótesis: Análisis de los 50 libros más vendidos en amazon (2009 - 2019)",
    "section": "5. Recapitulación y reflexiones",
    "text": "5. Recapitulación y reflexiones\nDurante la preparación de los datos:\n\nHemos realizado una limpieza en el dataset, reduciendo el número de muestras para el estudio de 549 a 331.\nHemos descubierto que user rating concentra sus muestras en 10 valores en lugar de los 50 esperados.\n\nDurante el estudio mediante test de hipótesis:\n\nHemos mostrado con significancia estadística que el género del libro influye tanto en el número de reviews como en el user rating.\nHemos mostrado con significancia estadística que el género del libro no influye en el precio del mismo."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Lorem ipsum dolor sit amet consectetur adipisicing elit. Maxime mollitia, molestiae quas vel sint commodi repudiandae consequuntur voluptatum laborum numquam blanditiis harum quisquam eius sed odit fugiat iusto fuga praesentium optio, eaque rerum! Provident similique accusantium nemo autem. Veritatis obcaecati tenetur iure eius earum ut molestias architecto voluptate aliquam nihil, eveniet aliquid culpa officia aut! Impedit sit sunt quaerat, odit, tenetur error, harum nesciunt ipsum debitis quas aliquid. Reprehenderit, quia. Quo neque error repudiandae fuga? Ipsa laudantium molestias eos sapiente officiis modi at sunt excepturi expedita sint? Sed quibusdam recusandae alias error harum maxime adipisci amet laborum. Perspiciatis minima nesciunt dolorem! Officiis iure rerum voluptates a cumque velit quibusdam sed amet tempora. Sit laborum ab, eius fugit doloribus tenetur fugiat, temporibus enim commodi iusto libero magni deleniti quod quam consequuntur! Commodi minima excepturi repudiandae velit hic maxime doloremque. Quaerat provident commodi consectetur veniam similique ad earum omnis ipsum saepe, voluptas, hic voluptates pariatur est explicabo fugiat, dolorum eligendi quam cupiditate excepturi mollitia maiores labore suscipit quas? Nulla, placeat. Voluptatem quaerat non architecto ab laudantium modi minima sunt esse temporibus sint culpa, recusandae aliquam numquam totam ratione voluptas quod exercitationem fuga. Possimus quis earum veniam quasi aliquam eligendi, placeat qui corporis!"
  },
  {
    "objectID": "posts/2023-11-14-health_insurance_hypothesis_testing/health-Insurance_hypothesis_testing.html",
    "href": "posts/2023-11-14-health_insurance_hypothesis_testing/health-Insurance_hypothesis_testing.html",
    "title": "Test de Hipótesis: explorando correlaciones en datos de seguros de salud",
    "section": "",
    "text": "From Kaggle: Health Insurance dataset\n\n\nDataset de una asegurada de salud. En las aseguradoras, la capacidad de predecir los costes de cada cliente es crucial. En función de estas predicciones ajustaran el precio de la póliza y el beneficio que obtendrán.\n\n\n\nVamos a responder a las siguientes preguntas con validez estadística:\n\n¿Los fumadores generan más gasto a la aseguradora que los no fumadores?\n¿Las mujeres tienen un BMI diferente a los hombres?\n¿La proporción de fumadores es diferente según la región?\n¿El promedio de BMI en las mujeres es diferente según el número de hijos que tengan?\n¿Es diferente la proporción de fumadores en ambos sexos?\n\n\n\n\n\n\n\nMatemáticas y código: en Inglés\n\n\n\n\n\nAunque el texto principal está en español, los términos matemáticos, los títulos de secciones y el código están en inglés.\nEsta práctica sigue el estándar internacional y ayuda a familiarizarse con el lenguaje técnico más utilizado en el campo de la ciencia de datos."
  },
  {
    "objectID": "posts/2023-11-14-health_insurance_hypothesis_testing/health-Insurance_hypothesis_testing.html#a.-entendimiento-del-negocio",
    "href": "posts/2023-11-14-health_insurance_hypothesis_testing/health-Insurance_hypothesis_testing.html#a.-entendimiento-del-negocio",
    "title": "Test de Hipótesis: explorando correlaciones en datos de seguros de salud",
    "section": "",
    "text": "From Kaggle: Health Insurance dataset\n\n\nDataset de una asegurada de salud. En las aseguradoras, la capacidad de predecir los costes de cada cliente es crucial. En función de estas predicciones ajustaran el precio de la póliza y el beneficio que obtendrán.\n\n\n\nVamos a responder a las siguientes preguntas con validez estadística:\n\n¿Los fumadores generan más gasto a la aseguradora que los no fumadores?\n¿Las mujeres tienen un BMI diferente a los hombres?\n¿La proporción de fumadores es diferente según la región?\n¿El promedio de BMI en las mujeres es diferente según el número de hijos que tengan?\n¿Es diferente la proporción de fumadores en ambos sexos?\n\n\n\n\n\n\n\nMatemáticas y código: en Inglés\n\n\n\n\n\nAunque el texto principal está en español, los términos matemáticos, los títulos de secciones y el código están en inglés.\nEsta práctica sigue el estándar internacional y ayuda a familiarizarse con el lenguaje técnico más utilizado en el campo de la ciencia de datos."
  },
  {
    "objectID": "posts/2023-11-14-health_insurance_hypothesis_testing/health-Insurance_hypothesis_testing.html#b.-entendimiento-de-los-datos",
    "href": "posts/2023-11-14-health_insurance_hypothesis_testing/health-Insurance_hypothesis_testing.html#b.-entendimiento-de-los-datos",
    "title": "Test de Hipótesis: explorando correlaciones en datos de seguros de salud",
    "section": "1b. Entendimiento de los datos",
    "text": "1b. Entendimiento de los datos\nPara empezar, importamos las librerías que vamos a utilizar:\n\nPandas: Pandas es una biblioteca esencial en la ciencia de datos que proporciona estructuras de datos flexibles y eficientes, como DataFrames, para el análisis y manipulación de datos tabulares. Es ampliamente utilizada para limpiar, transformar y analizar datos, lo que la convierte en una herramienta fundamental para la preparación de datos en proyectos de ciencia de datos.\nScipy: Scipy es una biblioteca que se construye sobre NumPy y ofrece una amplia variedad de módulos y funciones especializadas para aplicaciones científicas y matemáticas. Incluye herramientas para estadísticas, optimización, álgebra lineal y procesamiento de señales, lo que la hace esencial en la investigación y el análisis de datos en ciencia de datos.\nNumpy: NumPy es esencial en ciencia de datos para operaciones numéricas eficientes. Su estructura de matriz multidimensional permite cálculos y análisis de datos, siendo clave en manipulación y modelado.\nStatsmodels: Statsmodels se centra en proporcionar herramientas y modelos estadísticos para el análisis de datos. La usaremos únicamente para realizar un Two-Sample Proportion Test.\nPlotly Express: Plotly Express es una biblioteca de visualización de datos que simplifica la creación de gráficos interactivos y visuales. Es especialmente útil en la exploración de datos y la comunicación de resultados en ciencia de datos, permitiendo a los científicos de datos crear visualizaciones informativas y atractivas con facilidad.\n\n\n\nCode\n# Import libraries\nimport pandas as pd\nfrom scipy import stats\nimport numpy as np\n\nimport statsmodels.api as sm\n\n# Import plotly and customize\nimport plotly.io as pio\nimport plotly.express as px\n\npio.templates.default = \"plotly\"\npio.templates[\"plotly\"].layout.colorway = px.colors.qualitative.Set2\n\n\nCargamos el dataset y describimos brevemente sus características.\n\ndf = pd.read_csv(\"health_insurance.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCampo\nTipo de Dato\nDescripción\nEjemplo\n\n\n\n\nage\nNumérico (entero)\nEdad del asegurado\n29\n\n\nsex\nCategórico\nSexo del asegurado\nFemale/Male\n\n\nbmi\nNumérico\nÍndice de Masa Corporal del asegurado\n26.6\n\n\nchildren\nNumérico (entero)\nNúmero de hijos del asegurado\n2\n\n\nsmoker\nCategórico\nEstatus de fumador del asegurado\nNo/Yes\n\n\nregion\nCategórico\nRegión del asegurado\nSouthwest\n\n\ncharges\nNumérico (USD)\nCargos realizados a la compañía\n12345.67"
  },
  {
    "objectID": "posts/2023-11-14-health_insurance_hypothesis_testing/health-Insurance_hypothesis_testing.html#a.-preparación-de-los-datos",
    "href": "posts/2023-11-14-health_insurance_hypothesis_testing/health-Insurance_hypothesis_testing.html#a.-preparación-de-los-datos",
    "title": "Test de Hipótesis: explorando correlaciones en datos de seguros de salud",
    "section": "2a. Preparación de los datos",
    "text": "2a. Preparación de los datos\n\n2a.1 Typecasting\nComprobamos el tipo de datos de las columnas y los modificamos conforme nuestra descripción inicial.\n\ndf.dtypes\n\nage           int64\nsex          object\nbmi         float64\nchildren      int64\nsmoker       object\nregion       object\ncharges     float64\ndtype: object\n\n\n\ncategorical_columns = [\"sex\", \"smoker\", \"region\"]\ndf[categorical_columns] = df[categorical_columns].astype(\"category\")\n\n\ndf.dtypes\n\nage            int64\nsex         category\nbmi          float64\nchildren       int64\nsmoker      category\nregion      category\ncharges      float64\ndtype: object\n\n\n\n\n2a.2 Manejo de duplicados\n¿Cuantas filas son exactamente iguales?\n\ndf.duplicated().sum()\n\n1\n\n\n\ndf[df.duplicated(keep=False)]\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n195\n19\nmale\n30.59\n0\nno\nnorthwest\n1639.5631\n\n\n581\n19\nmale\n30.59\n0\nno\nnorthwest\n1639.5631\n\n\n\n\n\n\n\n\ndf[df[\"bmi\"] == 30.59]\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n195\n19\nmale\n30.59\n0\nno\nnorthwest\n1639.56310\n\n\n423\n25\nmale\n30.59\n0\nno\nnortheast\n2727.39510\n\n\n526\n19\nfemale\n30.59\n2\nno\nnorthwest\n24059.68019\n\n\n567\n41\nmale\n30.59\n2\nno\nnorthwest\n7256.72310\n\n\n581\n19\nmale\n30.59\n0\nno\nnorthwest\n1639.56310\n\n\n983\n27\nfemale\n30.59\n1\nno\nnortheast\n16796.41194\n\n\n1158\n20\nfemale\n30.59\n0\nno\nnortheast\n2459.72010\n\n\n\n\n\n\n\nVemos que las observaciones 195 y 581 tienen exactamente los mismos datos. Teniendo en cuenta que comparten el mismo “bmi” exacto con otras muchas observaciones. Vamos a valorar el duplicado como una casualidad. Por ello, vamos a mantenerlo en nuestro conjunto de datos.\n\n\n2a.3 Análisis de valores atípicos\nEn esta ocasión vamos a observar los outliers mediante dos métodos diferentes.\n\nUsando Z-Score\nUsando Z-Score: El Z-Score mide cuántas desviaciones estándar se encuentra un valor de la media. Valores que caen fuera de un rango de Z-Score específico se consideran outliers. Por ejemplo, un Z-Score de 2 indica que el valor está a dos desviaciones estándar de la media.\nEn general, un Z-Score de más de 3 se considera un outlier.\n\ndef identify_outliers(data, column_name, threshold=3):\n    z_scores = np.abs(stats.zscore(data[column_name]))\n    outliers = data[z_scores &gt; threshold]\n    return outliers\n\n\n# Identify outliers in 'age'\noutliers_age = identify_outliers(df, \"age\")\n\n# Identify outliers in 'bmi'\noutliers_bmi = identify_outliers(df, \"bmi\")\n\n# Identify outliers in 'charges'\noutliers_charges = identify_outliers(df, \"charges\")\n\nprint(\"Outliers in 'age':\")\nprint(outliers_age)\n\nprint(\"Outliers in 'bmi':\")\nprint(outliers_bmi)\n\nprint(\"Outliers in 'charges':\")\nprint(outliers_charges)\n\nOutliers in 'age':\nEmpty DataFrame\nColumns: [age, sex, bmi, children, smoker, region, charges]\nIndex: []\nOutliers in 'bmi':\n      age   sex    bmi  children smoker     region     charges\n116    58  male  49.06         0     no  southeast  11381.3254\n847    23  male  50.38         1     no  southeast   2438.0552\n1047   22  male  52.58         1    yes  southeast  44501.3982\n1317   18  male  53.13         0     no  southeast   1163.4627\nOutliers in 'charges':\n      age     sex     bmi  children smoker     region      charges\n34     28    male  36.400         1    yes  southwest  51194.55914\n543    54  female  47.410         0    yes  southeast  63770.42801\n577    31  female  38.095         1    yes  northeast  58571.07448\n819    33  female  35.530         0    yes  northwest  55135.40209\n1146   60    male  32.800         0    yes  southwest  52590.82939\n1230   52    male  34.485         3    yes  northwest  60021.39897\n1300   45    male  30.360         0    yes  southeast  62592.87309\n\n\n\n\nUsando boxplot y IQR\nIQR: El rango intercuartil (IQR) es la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1). Los valores que caen por debajo de Q1 - 1.5 * IQR o por encima de Q3 + 1.5 * IQR se consideran outliers.\nLos valores fuera del de este rango, son los que se representa como puntos en los boxplots.\n\n# create a boxplot with 'age', 'bmi' y 'charges' variables\nselected_columns = [\"age\", \"bmi\", \"charges\"]\n\nfor column in selected_columns:\n    fig = px.box(df, x=column, title=f\"Boxplot of {column}\")\n    fig.update_layout(title_x=0.5)\n    fig.show()\n\n\n                                                \n\n\n\n                                                \n\n\n\n                                                \n\n\n\n\nZ-score vs Boxplot\nPodemos ver como boxplot señala a más observaciones como outliers. En el caso de “bmi” las duplica, mientras que en “charges” son más del doble los detectados. Esto nos recuerda que juzgar una muestra como atípica, depende de nuestro método.\n\n\nIdeas destacadas\nAmbos métodos coinciden en: - “age”: no se detectan outliers - “BMI”: existen outliers, personas con una alta obesidad - “charges”: existen outliers, personas con cargos muy altos al seguro\nSe pueden hacer tres cosas con los outliers, siguiendo la mnemotecnia 3R: rectificar, retener o remover. En este caso, podemos estar ante valores atípicos genuinos, por tanto vamos a retenerlos por el momento.\n\n\n\n2a.4 Variables con varianza cercana a cero\nVariables númericas\n\nselected_columns = [\"age\", \"bmi\", \"children\", \"charges\"]\n\n# Calculate the variance for each column\nvariances = df[selected_columns].var()\n\n# Define a threshold for variance\nthreshold = 0.1\n\n# Identify columns with near-zero or very small variance\nzero_variance_cols = variances[variances &lt;= threshold].index\n\nprint(\"Columns with Zero & Near Zero Variance:\")\nprint(zero_variance_cols)\n\nColumns with Zero & Near Zero Variance:\nIndex([], dtype='object')\n\n\nVariables categoricas\n\nselected_columns = [\"sex\", \"smoker\", \"region\"]\n\n# Calculate the proportion of the most common category in each column\nprop_most_common = df[selected_columns].apply(\n    lambda col: col.value_counts().max() / len(col)\n)\n\n# Define a threshold for the proportion\nthreshold = 1\n\n# Identify columns with the proportion of the most common category close to 1\nzero_variance_cols = prop_most_common[prop_most_common &gt;= threshold].index\n\nprint(\"Columns with Zero & Near Zero Proportion:\")\nprint(zero_variance_cols)\n\nColumns with Zero & Near Zero Proportion:\nIndex([], dtype='object')\n\n\n\nIdeas destacadas\nNo se detectan variables con Zero & Near Zero Variance. A priori, todas las variables pueden estar aportando información.\n\n\n\n2a.5 Valores ausentes o faltantes\n\ndf.isnull().sum()\n\nage         0\nsex         0\nbmi         0\nchildren    0\nsmoker      0\nregion      0\ncharges     0\ndtype: int64\n\n\n\nIdeas destacadas\n\nNo hay missing values"
  },
  {
    "objectID": "posts/2023-11-14-health_insurance_hypothesis_testing/health-Insurance_hypothesis_testing.html#pruebas-de-hipótesis",
    "href": "posts/2023-11-14-health_insurance_hypothesis_testing/health-Insurance_hypothesis_testing.html#pruebas-de-hipótesis",
    "title": "Test de Hipótesis: explorando correlaciones en datos de seguros de salud",
    "section": "4. Pruebas de hipótesis",
    "text": "4. Pruebas de hipótesis\nVamos a responder a las siguientes preguntas con validez estadística:\n\n¿Los fumadores generan más gasto a la aseguradora que los no fumadores?\n¿Las mujeres tienen un BMI diferente a los hombres?\n¿La proporción de fumadores es diferente según la región?\n¿El promedio de BMI en las mujeres es diferente según el número de hijos que tengan?\n¿Es diferente la proporción de fumadores en ambos sexos?\n\n\n4.1 ¿Los fumadores generan más gasto a la aseguradora que los no fumadores?\nPrimero hagamos una exploración visual.\n\nfig = px.violin(\n    df,\n    x=\"charges\",\n    color=\"smoker\",\n    box=True,\n    points=\"outliers\",\n)\n\nfig.update_layout(\n    title_text=\"Charges violin plot by smoker status\",\n)\n\nfig.show()\n\n\n                                                \n\n\nEn este caso las diferencias entre ambos grupos son obvias. Pero para poder afirmarlo adecuadamente, debemos hacerlo con significancia estadística. Vamos a comprobarlo con un test de hipótesis.\n\n1. Seleccionamos la hipótesis y el nivel de significancia\nH0: El gasto medio de los fumadores es igual al de los no-fumadores\nHa: El gasto medio de los fumadores es diferente al de los no-fumadores\nalpha = 0.05\n\n\n2. Identificamos el tipo de test\nDeseamos comparar las medias de dos grupos de nuestra sample. Por lo tanto, un 2-Sample t-Test parece ser adecuado. Lo primero es verificar si se cumplen los requisitos del test.\n\n2.1 Requisitos del test\n\nTenemos una sample representativa de la population.\nLos datos son continuos.\nLas muestras siguen una distribución normal o hay más de 15 observaciones.\nLos grupos son independientes.\nLas varianzas son iguales (o al menos similares).\n\nExaminemos nuestra sample para ver si podemos aplicar el test.\n\n\n\n\n\n\nLibro de refencia\n\n\n\n\n\nBook: Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 48\nSection: 2-Sample t-Tests\n\n\n\nNúmero de observaciones para cada grupo:\n\ndf[\"smoker\"].value_counts()\n\nsmoker\nno     1064\nyes     274\nName: count, dtype: int64\n\n\nEn inspección visual de los datos, vemos que no siguen una distribución normal.\nEstudiemos la relación entre las varianzas de cada grupo.\n\nsmokers = df[df[\"smoker\"] == \"yes\"]\nnonsmokers = df[df[\"smoker\"] == \"no\"]\n\n\n# Perform the Levene's Test\nstatistic, p_value = stats.levene(smokers[\"charges\"], nonsmokers[\"charges\"])\n\n# Significance level\nalpha = 0.05\n\n# Check for significance\nif p_value &lt; alpha:\n    print(\"We reject the null hypothesis. The variances are not similar.\")\nelse:\n    print(\"We fail to reject the null hypothesis. The variances are similar.\")\n\nWe reject the null hypothesis. The variances are not similar.\n\n\nVolvamos sobre los requisitos del test:\n\n¿Tenemos una sample representativa de la population? Suponemos que sí.\n¿Los datos son continuos? Sí.\n¿Las muestras siguen una distribución normal o hay más de 15 observaciones?\n\nNo, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema central del límite podemos renunciar al supuesto de normalidad.\n\n¿Los grupos son independientes? Sí.\n¿Las varianzas son iguales (o al menos similares)?\n\nNo.\n\n\nNo cumplen los requisitos para realizar un 2-Sample t-Test. Vamos a realizar un test tipo Welch’s t-test.\nPara realizar el test utilizaremos scipy.stats.ttest_ind. Es necesario definir el parámetro equal_varbool como False.\n\n# Perform the Welch's t-test (equal_var=False)\nstatistic, p_value = stats.ttest_ind(\n    nonsmokers[\"charges\"], smokers[\"charges\"], equal_var=False\n)\n\n# Print the results\nprint(\"p-value:\", p_value)\n\n# Check for significance\nalpha = 0.05  # Significance level\nif p_value &lt; alpha:\n    print(\n        \"We reject the null hypothesis. There are significant differences between the groups.\"\n    )\nelse:\n    print(\n        \"We fail to reject the null hypothesis. There are no significant differences between the groups.\"\n    )\n\np-value: 5.88946444671698e-103\nWe reject the null hypothesis. There are significant differences between the groups.\n\n\n\n\n\nIdeas destacadas\nComo ya nos adelantaba la exploración visual, rechazamos la hipótesis nula. Tenemos evidencia suficiente (95% y 99%) para demostrar que existe una diferencia en los cargos de fumadores y no fumadores.\n\n\n\n4.2 ¿Las mujeres tienen un BMI diferente a los hombres?\nPrimero hagamos una exploración visual.\n\nfig = px.violin(\n    df,\n    x=\"bmi\",\n    color=\"sex\",\n    box=True,\n    points=\"outliers\",\n)\n\nfig.update_layout(\n    title_text=\"Charges violin plot by smoker status\",\n)\n\nfig.show()\n\n\n                                                \n\n\nEn esta ocasión “bmi” podría no variar en función de “sex”. ¿Pero es estadísticamente significativo? Vamos a comprobarlo con un test de hipótesis.\n\n1. Seleccionamos la hipótesis y el nivel de significancia\nH0: El BMI medio de las mujeres es igual al de los hombres\nHa: El BMI medio de las mujeres es diferente al de los hombres\nalpha = 0.05\n\n\n2. Identificamos el tipo de test\nDeseamos comparar las medias de dos grupos de nuestra sample. Por lo tanto, un 2-Sample t-Test parece ser adecuado. Lo primero es verificar si se cumplen los requisitos del test.\n\n2.1 Requisitos del test\n\nTenemos una sample representativa de la population.\nLos datos son continuos.\nLas muestras siguen una distribución normal o hay más de 15 observaciones.\nLos grupos son independientes.\nLas varianzas son iguales (o al menos similares).\n\nExaminemos nuestra sample para ver si podemos aplicar el test.\n\n\n\n\n\n\nLibro de refencia\n\n\n\n\n\nBook: Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 48\nSection: 2-Sample t-Tests\n\n\n\nNúmero de observaciones para cada grupo:\n\ndf[\"sex\"].value_counts()\n\nsex\nmale      676\nfemale    662\nName: count, dtype: int64\n\n\nRealizamos un test de normalidad para cada grupo.\n\nmen = df[df[\"sex\"] == \"male\"]\nwomen = df[df[\"sex\"] == \"female\"]\n\n\ndef shapiro_test(data, alpha=0.05):\n    \"\"\"\n    Perform the Shapiro-Wilk test to check the normality of the data.\n\n    Parameters:\n    data (array-like): The data to analyze.\n    alpha (float): Significance level.\n\n    Returns:\n    str: The test result.\n    \"\"\"\n    statistic, p_value = stats.shapiro(data)\n\n    if p_value &lt; alpha:\n        return \"We reject the null hypothesis. The data does not follow a normal distribution.\"\n    else:\n        return \"We fail to reject the null hypothesis. The data can be considered normally distributed.\"\n\n\n# Run the Shapiro-Wilk test\nresult_men = shapiro_test(men[\"charges\"])\nresult_women = shapiro_test(women[\"charges\"])\n\nprint(\"For men:\", result_men)\nprint(\"For women:\", result_women)\n\nFor men: We reject the null hypothesis. The data does not follow a normal distribution.\nFor women: We reject the null hypothesis. The data does not follow a normal distribution.\n\n\nEstudiemos la relación entre las varianzas de cada grupo.\n\n# Perform the Levene's Test\nstatistic, p_value = stats.levene(men[\"bmi\"], women[\"bmi\"])\n\n# Significance level\nalpha = 0.05\n\n# Check for significance\nif p_value &lt; alpha:\n    print(\"We reject the null hypothesis. The variances are not similar.\")\nelse:\n    print(\"We fail to reject the null hypothesis. The variances are similar.\")\n\nWe fail to reject the null hypothesis. The variances are similar.\n\n\nVolvamos sobre los requisitos del test:\n\n¿Tenemos una sample representativa de la population? Suponemos que sí.\n¿Los datos son continuos? Sí.\n¿Las muestras siguen una distribución normal o hay más de 15 observaciones?\n\nNo, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema central del límite podemos renunciar al supuesto de normalidad.\n\n¿Los grupos son independientes? Sí.\n¿Las varianzas son iguales (o al menos similares)? Sí.\n\nSe cumplen los requisitos para realizar un 2-Sample t-Test.\nPara realizar el test vamos a usar scipy.stats.ttest_ind.\n\n# Realiza el test t de Welch (equal_var=False)\nstatistic, p_value = stats.ttest_ind(men[\"bmi\"], women[\"bmi\"])\n\n# Check for significance\nalpha = 0.05  # Significance level\nif p_value &lt; alpha:\n    print(\n        \"We reject the null hypothesis. There are significant differences between the groups.\"\n    )\nelse:\n    print(\n        \"We fail to reject the null hypothesis. There are no significant differences between the groups.\"\n    )\n\nWe fail to reject the null hypothesis. There are no significant differences between the groups.\n\n\n\n\n\nIdeas destacadas\nNo tenemos evidencia suficiente para rechazar la hipótesis nula. No podemos afirmar que exista una diferencia en el BMI medio de hombres y mujeres.\n\n\n\n4.3 ¿La proporción de fumadores es diferente según la región?\n\n# Calculate the proportion of smokers by region\nsmokers_by_region = (\n    df.groupby(\"region\")[\"smoker\"]\n    .value_counts(normalize=True)\n    .rename(\"proportion\")\n    .reset_index()\n)\n\n# Create a bar chart to show the proportion of smokers by region\nfig = px.bar(\n    smokers_by_region,\n    x=\"region\",\n    y=\"proportion\",\n    color=\"smoker\",\n    title=\"Proportion of Smokers by Region\",\n    labels={\n        \"proportion\": \"Proportion of Policyholders\",\n        \"smoker\": \"Smoker\",\n        \"region\": \"Region\",\n    },\n    category_orders={\"smoker\": [\"yes\", \"no\"]},\n)  # Order the legend\n\n# Adjust the text to display the proportions as percentages and ensure it's inside the bar for better readability\nfig.update_traces(texttemplate=\"%{y:.1%}\", textposition=\"inside\")\n\nfig.show()\n\n\n                                                \n\n\nLa máxima diferencia entre regiones es de un 7.2%. ¿Es suficiente para afirmar que la proporción es diferente según la región? Vamos a comprobarlo con un test de hipótesis.\n\n1. Seleccionamos la hipótesis y el nivel de significancia\nH0: No existe una diferencia en la proporción de fumadores según la región. Es decir, las variables son independientes.\nHa: Existe una diferencia en la proporción de fumadores según la región\nalpha = 0.05\n\n\n2. Identificamos el tipo de test\nQueremos determinar si existe una relación estadísticamente significativa entre dos variables categóricas. Por lo que un Chi-Square Test parece lo adecuado.\n\n2.1 Requisitos del test\n\nLas variables son categóricas.\nLas observaciones son independientes.\nCada celda de la tabla de contingencia tiene un valor esperado de al menos 5.\n\nExaminemos nuestra sample para ver si podemos aplicar el test.\n\n\n\n\n\n\nLibro de refencia\n\n\n\n\n\nBook: Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 315\nSection: Chi-Square Tests of Independence\n\n\n\nCreamos la tabla de contingencia.\n\ncontingency_table = pd.crosstab(df[\"region\"], df[\"smoker\"])\ncontingency_table\n\n\n\n\n\n\n\nsmoker\nno\nyes\n\n\nregion\n\n\n\n\n\n\nnortheast\n257\n67\n\n\nnorthwest\n267\n58\n\n\nsoutheast\n273\n91\n\n\nsouthwest\n267\n58\n\n\n\n\n\n\n\nVolvamos sobre los requisitos del test:\n\n¿Las variables son categóricas? Sí.\n¿Las observaciones son independientes? Sí.\n¿Cada celda de la tabla de contingencia tiene un valor esperado de al menos 5? Sí.\n\nSe cumplen los requisitos para realizar un Chi-Square Test.\nPara realizar el test utilizaremos stats.chi2_contingency.\n\n# Perform the Chi-square independence test\nc, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n\nprint(\"P-value:\", p_value)\n\n# Check for significance\nalpha = 0.05  # Significance level\nif p_value &lt; alpha:\n    print(\n        \"We reject the null hypothesis. There is a relationship between the variables.\"\n    )\nelse:\n    print(\"We fail to reject the null hypothesis\")\n\nP-value: 0.06171954839170541\nWe fail to reject the null hypothesis\n\n\n\n\n\nIdeas destacadas\nFallamos al rechazar la hipótesis nula. No podemos concluir que no existe relación entre fumadores y la región.\n\n\n\n4.4 ¿El promedio de BMI en las mujeres es diferente según el número de hijos que tengan?\nEn este caso vamos a trabajar con los datos de las mujeres que tienen entre 0 y 2 hijos.\n\nwomen_few_children_df = df.loc[\n    (df[\"sex\"] == \"female\") & (df[\"children\"].isin([0, 1, 2]))\n]\n\nPrimero hagamos una exploración visual.\n\nfig = px.violin(\n    women_few_children_df,\n    x=\"bmi\",\n    color=\"children\",\n    box=True,\n    points=\"outliers\",\n)\n\nfig.update_layout(\n    title_text=\"BMI violin plot by children\",\n)\n\nfig.show()\n\n\n                                                \n\n\nParece que no existen grandes diferencias. ¿Pero es estadísticamente significativo? Vamos a comprobarlo con un test de hipótesis.\n\n1. Seleccionamos la hipótesis y el nivel de significancia\nH0: Los tres grupos tienen el mismo promedio de BMI\nHa: Al menos uno de los grupos tiene un promedio de BMI diferente\nalpha = 0.05\n\n\n2. Identificamos el tipo de test\nDeseamos comparar las medias de tres grupos de nuestra muestra. Por lo que un One-Way ANOVA parece lo adecuado. Lo primero es ver si se cumplen los requisitos del test.\n\n2.1 Requisitos del test\n\nLa variable dependiente es continua.\nLa variable independiente es categórica.\nLas muestras siguen una distribución normal o hay más de 20 observaciones.\nLos grupos son independientes.\nLas varianzas son similares.\n\nExaminemos nuestra sample para ver si podemos aplicar el test.\n\n\n\n\n\n\nLibro de refencia\n\n\n\n\n\nBook: Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 197\nSection: One-Way ANOVA\n\n\n\nNúmero de observaciones para cada grupo:\n\nwomen_few_children_df[\"children\"].value_counts()\n\nchildren\n0    289\n1    158\n2    119\nName: count, dtype: int64\n\n\n\n# Run the Shapiro-Wilk test\nresult_zero = shapiro_test(df[df[\"children\"] == 0][\"bmi\"])\nresult_one = shapiro_test(df[df[\"children\"] == 1][\"bmi\"])\nresult_two = shapiro_test(df[df[\"children\"] == 2][\"bmi\"])\n\nprint(\"For zero child:\", result_zero)\nprint(\"For one child:\", result_one)\nprint(\"For two children:\", result_two)\n\nFor zero child: We reject the null hypothesis. The data does not follow a normal distribution.\nFor one child: We reject the null hypothesis. The data does not follow a normal distribution.\nFor two children: We fail to reject the null hypothesis. The data can be considered normally distributed.\n\n\n\n# Perform the Levene's Test\nstatistic, p_value = stats.levene(\n    df[df[\"children\"] == 0][\"bmi\"],\n    df[df[\"children\"] == 1][\"bmi\"],\n    df[df[\"children\"] == 2][\"bmi\"],\n)\n\n# Significance level\nalpha = 0.05\n\n# Check for significance\nif p_value &lt; alpha:\n    print(\"We reject the null hypothesis. The variances are not similar.\")\nelse:\n    print(\"We fail to reject the null hypothesis. The variances are similar.\")\n\nWe fail to reject the null hypothesis. The variances are similar.\n\n\nVolvamos sobre los requisitos del test:\n\n¿La variable dependiente es continua? Sí.\n¿La variable independiente es categórica? Sí.\n¿Las muestras siguen una distribución normal o hay más de 20 observaciones\n\nNo, las muestras no siguen una distribución normal. Pero hay más de 20 observaciones en cada grupo, gracias al teorema central del límite podemos renunciar al supuesto de normalidad.\n\n¿Los grupos son independientes? Sí.\n¿Las varianzas son similares? Sí.\n\nSe cumplen los requisitos para realizar un One-Way ANOVA.\nPara realizar el test utilizaremos scipy.stats.f_oneway.\n\nf_statistic, p_value = stats.f_oneway(\n    df[df[\"children\"] == 0][\"bmi\"],\n    df[df[\"children\"] == 1][\"bmi\"],\n    df[df[\"children\"] == 2][\"bmi\"],\n)\n\n# Check for significance\nalpha = 0.05  # Significance level\nif p_value &lt; alpha:\n    print(\n        \"We reject the null hypothesis. There are significant differences between the groups.\"\n    )\nelse:\n    print(\n        \"We fail to reject the null hypothesis. There are no significant differences between the groups.\"\n    )\n\nWe fail to reject the null hypothesis. There are no significant differences between the groups.\n\n\n\n\n\nIdeas destacadas\nFallamos al rechazar la hipótesis nula. No hay diferencias en el BMI en función del número de hijos.\n\n\n\n4.5 ¿Es diferente la proporción de fumadores en ambos sexos?\nPrimero hagamos una exploración visual.\n\n# Calculate the proportion of smokers by sex\nsmokers_by_sex = (\n    df.groupby(\"sex\")[\"smoker\"]\n    .value_counts(normalize=True)\n    .rename(\"proportion\")\n    .reset_index()\n)\n\n# Create a bar chart to show the proportion of smokers by sex\nfig = px.bar(\n    smokers_by_sex,\n    x=\"sex\",\n    y=\"proportion\",\n    color=\"smoker\",\n    title=\"Proportion of Smokers by sex\",\n    labels={\n        \"proportion\": \"Proportion of Policyholders\",\n        \"smoker\": \"Smoker\",\n        \"sex\": \"sex\",\n    },\n    category_orders={\"smoker\": [\"yes\", \"no\"]},\n)  # Order the legend\n\n# Adjust the text to display the proportions as percentages and ensure it's inside the bar for better readability\nfig.update_traces(texttemplate=\"%{y:.1%}\", textposition=\"inside\")\n\nfig.show()\n\n\n                                                \n\n\nParece que existen diferencias. ¿Pero son estadísticamente significativas? Vamos a comprobarlo con un test de hipótesis.\n\n1. Seleccionamos la hipótesis y el nivel de significancia\nH0: La proporcion de fumadores es igual en ambos sexos.\nHa: La proporcion de fumadores es diferente.\nalpha = 0.05\n\n\n2. Identificamos el tipo de test\nDeseamos comparar la proporción en dos variables binarias. Por lo que un Two-Sample Proportion Test parece lo adecuado. Lo primero es ver si se cumplen los requisitos del test.\n\n2.1 Requisitos del test\n\nVariables binarias.\nGrupos independientes.\nCada muestra es independiente.\nLas proporciones se mantienen constantes en el tiempo.\n\nExaminemos nuestra sample para ver si podemos aplicar el test.\n\n\n\n\n\n\nLibro de refencia\n\n\n\n\n\nBook: Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 283\nSection: Two-Sample Proportion Test\n\n\n\nVolvamos sobre los requisitos del test:\n\n¿Variables binarias? Sí.\n¿Grupos independientes? Sí.\n¿Cada muestra es independiente? Sí.\n¿Las proporciones se mantienen constantes en el tiempo? Sí.\n\nSe cumplen los requisitos para realizar un Two-Sample Proportion Test.\nPara realizar el test vamos a usar statsmodels.stats.proportion.proportions_ztest.\n\ncontingency_table = pd.crosstab(df[\"sex\"], df[\"smoker\"])\ncontingency_table\n\n\n\n\n\n\n\nsmoker\nno\nyes\n\n\nsex\n\n\n\n\n\n\nfemale\n547\n115\n\n\nmale\n517\n159\n\n\n\n\n\n\n\n\n# Create two groups based on \"sex\" and \"smoker\"\ngroup1 = df[(df[\"sex\"] == \"female\") & (df[\"smoker\"] == \"yes\")]\ngroup2 = df[(df[\"sex\"] == \"female\") & (df[\"smoker\"] == \"no\")]\n\n# Count the number of observations in each group\ncount1 = len(group1)\ncount2 = len(group2)\n\n# Count the number of smokers (successes) in each group\nsuccess1 = len(group1[group1[\"smoker\"] == \"yes\"])\nsuccess2 = len(group2[group2[\"smoker\"] == \"yes\"])\n\n# Perform the Two-Sample Proportions Test\nstat, p_value = sm.stats.proportions_ztest([success1, success2], [count1, count2])\n\n# Check for significance\nalpha = 0.05\n\nif p_value &lt; alpha:\n    print(\n        \"We reject the null hypothesis. There are significant differences in proportions between sexes.\"\n    )\nelse:\n    print(\n        \"We fail to reject the null hypothesis. There are no significant differences in proportions between sexes.\"\n    )\n\nWe reject the null hypothesis. There are significant differences in proportions between sexes.\n\n\n\n\n\nIdeas destacadas\nRechazamos la hipótesis nula. Existen diferencias en a proporción de fumadores entre ambos sexos."
  },
  {
    "objectID": "posts/2023-11-14-health_insurance_hypothesis_testing/health-Insurance_hypothesis_testing.html#recapitulación-y-reflexiones",
    "href": "posts/2023-11-14-health_insurance_hypothesis_testing/health-Insurance_hypothesis_testing.html#recapitulación-y-reflexiones",
    "title": "Test de Hipótesis: explorando correlaciones en datos de seguros de salud",
    "section": "5. Recapitulación y reflexiones",
    "text": "5. Recapitulación y reflexiones\nRepasemos nuestras preguntas iniciales y lo que hemos averiguado al respecto:\n\n¿Los fumadores generan más gasto a la aseguradora que los no fumadores?\n\nSí, con una evidencia muy alta.\n\n¿Las mujeres tienen un BMI diferente a los hombres?\n\nNo, no podemos afirmar que exista una diferencia en el BMI medio de hombres y mujeres.\n\n¿La proporción de fumadores es diferente según la región?\n\nNo, no podemos concluir que no existe relación entre fumadores y región.\n\n¿El promedio de BMI en las mujeres es diferente según el número de hijos que tengan?\n\nNo, no hay diferencias en el BMI en función del número de hijos.\n\n¿Es diferente la proporción de fumadores en ambos sexos?\n\nSí, los hombres tienen una mayor proporción de fumadores."
  }
]