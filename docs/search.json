[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Blog",
    "section": "",
    "text": "Exploring Hypothesis Testing: A Series for Beginners 1\n\n\n\n\n\n\n\nEDA\n\n\nhypothesis-testing\n\n\n\n\nA series of posts exploring hypothesis testing for beginners.\n\n\n\n\n\n\nOct 16, 2023\n\n\nMicael García\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html",
    "href": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html",
    "title": "Exploring Hypothesis Testing: A Series for Beginners 1",
    "section": "",
    "text": "dataset source: https://www.kaggle.com/datasets/sootersaalu/amazon-top-50-bestselling-books-2009-2019/data\n\n\nDatos sobre los 50 libros más vendidos en Amazon de 2009 a 2019.\n\n\n\nVamos a responder a las siguientes preguntas con validez estadística:\n\n¿Los géneros difieren en User Rating?\n¿Los géneros difieren en número de Reviews?\n¿Los géneros difieren en términos de precio?\n\n\n\n\n\n\n\nTip with Title\n\n\n\nThis is an example of a callout with a title.\n\n\n\n\n\n\n\n# Import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n\n\n\ndf = pd.read_csv(\"bestsellers with categories.csv\")\ndf.head(10)\n\n\n\n\n\n\n\n\nName\nAuthor\nUser Rating\nReviews\nPrice\nYear\nGenre\n\n\n\n\n0\n10-Day Green Smoothie Cleanse\nJJ Smith\n4.7\n17350\n8\n2016\nNon Fiction\n\n\n1\n11/22/63: A Novel\nStephen King\n4.6\n2052\n22\n2011\nFiction\n\n\n2\n12 Rules for Life: An Antidote to Chaos\nJordan B. Peterson\n4.7\n18979\n15\n2018\nNon Fiction\n\n\n3\n1984 (Signet Classics)\nGeorge Orwell\n4.7\n21424\n6\n2017\nFiction\n\n\n4\n5,000 Awesome Facts (About Everything!) (Natio...\nNational Geographic Kids\n4.8\n7665\n12\n2019\nNon Fiction\n\n\n5\nA Dance with Dragons (A Song of Ice and Fire)\nGeorge R. R. Martin\n4.4\n12643\n11\n2011\nFiction\n\n\n6\nA Game of Thrones / A Clash of Kings / A Storm...\nGeorge R. R. Martin\n4.7\n19735\n30\n2014\nFiction\n\n\n7\nA Gentleman in Moscow: A Novel\nAmor Towles\n4.7\n19699\n15\n2017\nFiction\n\n\n8\nA Higher Loyalty: Truth, Lies, and Leadership\nJames Comey\n4.7\n5983\n3\n2018\nNon Fiction\n\n\n9\nA Man Called Ove: A Novel\nFredrik Backman\n4.6\n23848\n8\n2016\nFiction\n\n\n\n\n\n\n\n\nName\n\nTítulo del libro\nUnidad: texto (categoría)\n\nAuthor\n\nNombre del autor\nUnidad: texto (categoría)\n\nUser Rating\n\nCalificación promedio del libro por los usuarios\nUnidad: número entre 0 y 5 (con decimales)\n\nReviews\n\nNúmero de reseñas\nUnidad: número entero\n\nPrice\n\nPrecio del libro\nUnidad: número entero\n\nYear\n\nAño en el que el libro fue de los más vendidos\nUnidad: año (número entero)\n\nGenre\n\nGénero del libro simplificado (Fiction o Non Fiction)\nUnidad: categorico con dos valores posibles\n\n\n\n\n\n\n\n\n\n# comprobamos el tipo de datos de las columnas\ndf.dtypes\n\nName            object\nAuthor          object\nUser Rating    float64\nReviews          int64\nPrice            int64\nYear             int64\nGenre           object\ndtype: object\n\n\n\ncolumnas_categoricas = [\"Genre\", \"Name\", \"Author\"]\ndf[columnas_categoricas] = df[columnas_categoricas].astype(\"category\")\n\n\ndf.dtypes\n\nName           category\nAuthor         category\nUser Rating     float64\nReviews           int64\nPrice             int64\nYear              int64\nGenre          category\ndtype: object\n\n\n\n\n\nComprobar si hay autores o títulos iguales pero escritos diferente.\n\nfrom fuzzywuzzy import fuzz\n\n\n# Función para encontrar nombres de autores similares\ndef encontrar_similares(df, columna):\n    autores = df[columna].unique()\n    duplicados = []\n\n    for i, autor1 in enumerate(autores):\n        for autor2 in autores[i + 1 :]:\n            ratio = fuzz.ratio(autor1, autor2)\n            if ratio &gt; 90:  # Puedes ajustar este umbral según tu criterio\n                duplicados.append((autor1, autor2))\n\n    return duplicados\n\n\n# Encuentra nombres de autores similares\nduplicados = encontrar_similares(df, \"Author\")\n\nprint(\n    \"Nombres de autores que se refieren al mismo autor pero están escritos diferente:\"\n)\nfor dup in duplicados:\n    print(dup)\n\nNombres de autores que se refieren al mismo autor pero están escritos diferente:\n('George R. R. Martin', 'George R.R. Martin')\n('J.K. Rowling', 'J. K. Rowling')\n\n\n\n# Replace the names of the Authors with the correct ones\ndf = df.replace(\"George R. R. Martin\", \"George R.R. Martin\")\ndf = df.replace(\"J. K. Rowling\", \"J.K. Rowling\")\n\n\n# Encuentra nombres de títulos similares\nduplicados = encontrar_similares(df, \"Name\")\n\nprint(\n    \"Nombres de autores que se refieren al mismo autor pero están escritos diferente:\"\n)\nfor dup in duplicados:\n    print(dup)\n\nNombres de autores que se refieren al mismo autor pero están escritos diferente:\n('The 5 Love Languages: The Secret to Love That Lasts', 'The 5 Love Languages: The Secret to Love that Lasts')\n('The Girl Who Played with Fire (Millennium Series)', 'The Girl Who Played with Fire (Millennium)')\n\n\n\n# Replace the names of the Authors with the correct ones\ndf = df.replace(\n    \"The 5 Love Languages: The Secret to Love That Lasts\",\n    \"The 5 Love Languages: The Secret to Love that Lasts\",\n)\ndf = df.replace(\n    \"The Girl Who Played with Fire (Millennium Series)\",\n    \"The Girl Who Played with Fire (Millennium)\",\n)\n\n\ndf\n\n\n\n\n\n\n\n\nName\nAuthor\nUser Rating\nReviews\nPrice\nYear\nGenre\n\n\n\n\n0\n10-Day Green Smoothie Cleanse\nJJ Smith\n4.7\n17350\n8\n2016\nNon Fiction\n\n\n1\n11/22/63: A Novel\nStephen King\n4.6\n2052\n22\n2011\nFiction\n\n\n2\n12 Rules for Life: An Antidote to Chaos\nJordan B. Peterson\n4.7\n18979\n15\n2018\nNon Fiction\n\n\n3\n1984 (Signet Classics)\nGeorge Orwell\n4.7\n21424\n6\n2017\nFiction\n\n\n4\n5,000 Awesome Facts (About Everything!) (Natio...\nNational Geographic Kids\n4.8\n7665\n12\n2019\nNon Fiction\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n545\nWrecking Ball (Diary of a Wimpy Kid Book 14)\nJeff Kinney\n4.9\n9413\n8\n2019\nFiction\n\n\n546\nYou Are a Badass: How to Stop Doubting Your Gr...\nJen Sincero\n4.7\n14331\n8\n2016\nNon Fiction\n\n\n547\nYou Are a Badass: How to Stop Doubting Your Gr...\nJen Sincero\n4.7\n14331\n8\n2017\nNon Fiction\n\n\n548\nYou Are a Badass: How to Stop Doubting Your Gr...\nJen Sincero\n4.7\n14331\n8\n2018\nNon Fiction\n\n\n549\nYou Are a Badass: How to Stop Doubting Your Gr...\nJen Sincero\n4.7\n14331\n8\n2019\nNon Fiction\n\n\n\n\n550 rows × 7 columns\n\n\n\n\n# número de filas duplicadas\ndf.duplicated().sum()\n\n0\n\n\nEs normal no encontrar duplicados en este caso, hay libros que se repiten pero es imposible que coincidan en “Year”. No es un error por si mismo. Pero hay un problema. Las “Reviews” deberían ser las que el libro tenia el año en el que fue de los mas vendidos. En lugar de eso son las del último año. Esto puede deberse a que el autor del dataset no tuvo acceso al historial de las reseñas.\nEs importante tener en cuenta esto para el análisis.\nVamos a utilizar unicamente la muestra más reciente de cada libro.\n\n# todos los libros con el titulo repetido\ndf[df.duplicated(\"Name\")].head(20)\n\n\n\n\n\n\n\n\nName\nAuthor\nUser Rating\nReviews\nPrice\nYear\nGenre\n\n\n\n\n10\nA Man Called Ove: A Novel\nFredrik Backman\n4.6\n23848\n8\n2017\nFiction\n\n\n21\nAll the Light We Cannot See\nAnthony Doerr\n4.6\n36348\n14\n2015\nFiction\n\n\n33\nBecoming\nMichelle Obama\n4.8\n61133\n11\n2019\nNon Fiction\n\n\n36\nBetween the World and Me\nTa-Nehisi Coates\n4.7\n10070\n13\n2016\nNon Fiction\n\n\n41\nBrown Bear, Brown Bear, What Do You See?\nBill Martin Jr.\n4.9\n14344\n5\n2019\nFiction\n\n\n47\nCatching Fire (The Hunger Games)\nSuzanne Collins\n4.7\n22614\n11\n2011\nFiction\n\n\n48\nCatching Fire (The Hunger Games)\nSuzanne Collins\n4.7\n22614\n11\n2012\nFiction\n\n\n51\nCrazy Love: Overwhelmed by a Relentless God\nFrancis Chan\n4.7\n1542\n14\n2010\nNon Fiction\n\n\n52\nCrazy Love: Overwhelmed by a Relentless God\nFrancis Chan\n4.7\n1542\n14\n2011\nNon Fiction\n\n\n57\nCutting for Stone\nAbraham Verghese\n4.6\n4866\n11\n2011\nFiction\n\n\n64\nDear Zoo: A Lift-the-Flap Book\nRod Campbell\n4.8\n10922\n5\n2016\nFiction\n\n\n65\nDear Zoo: A Lift-the-Flap Book\nRod Campbell\n4.8\n10922\n5\n2017\nFiction\n\n\n66\nDear Zoo: A Lift-the-Flap Book\nRod Campbell\n4.8\n10922\n5\n2018\nFiction\n\n\n70\nDiagnostic and Statistical Manual of Mental Di...\nAmerican Psychiatric Association\n4.5\n6679\n105\n2014\nNon Fiction\n\n\n76\nDivergent\nVeronica Roth\n4.6\n27098\n15\n2014\nFiction\n\n\n84\nDog Man: Brawl of the Wild: From the Creator o...\nDav Pilkey\n4.9\n7235\n4\n2019\nFiction\n\n\n94\nEat to Live: The Amazing Nutrient-Rich Program...\nJoel Fuhrman MD\n4.5\n6346\n9\n2012\nNon Fiction\n\n\n98\nEducated: A Memoir\nTara Westover\n4.7\n28729\n15\n2019\nNon Fiction\n\n\n101\nFahrenheit 451\nRay Bradbury\n4.6\n10721\n8\n2018\nFiction\n\n\n107\nFifty Shades of Grey: Book One of the Fifty Sh...\nE L James\n3.8\n47265\n14\n2013\nFiction\n\n\n\n\n\n\n\n\n# Drop duplicates\nbestsellers = df.drop_duplicates(subset=\"Name\", keep=\"last\")\nbestsellers\n\n\n\n\n\n\n\n\nName\nAuthor\nUser Rating\nReviews\nPrice\nYear\nGenre\n\n\n\n\n0\n10-Day Green Smoothie Cleanse\nJJ Smith\n4.7\n17350\n8\n2016\nNon Fiction\n\n\n1\n11/22/63: A Novel\nStephen King\n4.6\n2052\n22\n2011\nFiction\n\n\n2\n12 Rules for Life: An Antidote to Chaos\nJordan B. Peterson\n4.7\n18979\n15\n2018\nNon Fiction\n\n\n3\n1984 (Signet Classics)\nGeorge Orwell\n4.7\n21424\n6\n2017\nFiction\n\n\n4\n5,000 Awesome Facts (About Everything!) (Natio...\nNational Geographic Kids\n4.8\n7665\n12\n2019\nNon Fiction\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n538\nWinter of the World: Book Two of the Century T...\nKen Follett\n4.5\n10760\n15\n2012\nFiction\n\n\n539\nWomen Food and God: An Unexpected Path to Almo...\nGeneen Roth\n4.2\n1302\n11\n2010\nNon Fiction\n\n\n544\nWonder\nR. J. Palacio\n4.8\n21625\n9\n2017\nFiction\n\n\n545\nWrecking Ball (Diary of a Wimpy Kid Book 14)\nJeff Kinney\n4.9\n9413\n8\n2019\nFiction\n\n\n549\nYou Are a Badass: How to Stop Doubting Your Gr...\nJen Sincero\n4.7\n14331\n8\n2019\nNon Fiction\n\n\n\n\n349 rows × 7 columns\n\n\n\nResumen: - Hemos corregido los errores ortográficos de los títulos y autores. - Hemos seleccionado las muestras más recientes de cada libro.\nHemos reducido el tamaño del dataset de 550 a 349 muestras.\n\n\n\n\n\nIQR: El rango intercuartil (IQR) es la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1). Los valores que caen por debajo de Q1 - 1.5 * IQR o por encima de Q3 + 1.5 * IQR se consideran outliers.\nLos valores fuera del de este rango, son los que se representa como puntos en los bloxpots.\n\nimport plotly.express as px\n\nselected_columns = [\"Reviews\", \"Price\"]\n\nfor column in selected_columns:\n    fig = px.box(df, x=column, title=f\"Boxplot of {column}\")\n    fig.update_layout(title_x=0.5)  # Centra el título\n    fig.show()\n\n\n                                                \n\n\n\n                                                \n\n\nObservaciones:\n\nage: no se detectan outliers\nBMI: existen outliers, personas con una alta obesidad\ncharges: existen outliers, personas con cargos muy altos al seguro\n\n\n\n\n\n\nbestsellers.describe()\n\n\n\n\n\n\n\n\nUser Rating\nReviews\nPrice\nYear\n\n\n\n\ncount\n349.000000\n349.000000\n349.000000\n349.000000\n\n\nmean\n4.608596\n9811.922636\n12.962751\n2014.128940\n\n\nstd\n0.227266\n10899.783863\n10.011562\n3.377239\n\n\nmin\n3.300000\n37.000000\n0.000000\n2009.000000\n\n\n25%\n4.500000\n3428.000000\n8.000000\n2011.000000\n\n\n50%\n4.600000\n6310.000000\n11.000000\n2014.000000\n\n\n75%\n4.800000\n11550.000000\n16.000000\n2017.000000\n\n\nmax\n4.900000\n87841.000000\n105.000000\n2019.000000\n\n\n\n\n\n\n\nVariables númericas\n\nselected_columns = [\"User Rating\", \"Reviews\", \"Price\"]\n\n# Calcular la varianza de cada columna\nvariances = bestsellers[selected_columns].var()\n\n# Definir un umbral para la varianza\nthreshold = 0.1\n\n# Identificar las columnas con varianza cercana a cero o muy pequeña\nzero_variance_cols = variances[variances &lt;= threshold].index\n\nprint(\"Columnas con Zero & Near Zero Variance:\")\nprint(zero_variance_cols)\n\nColumnas con Zero & Near Zero Variance:\nIndex(['User Rating'], dtype='object')\n\n\nVariables categoricas. No tiene sentido en este analisis en este caso.\nObserviaciones:\n\nNo se detectan variables con Zero & Near Zero Variance\n\n\n\n\n\nbestsellers.isnull().sum()\n\nName           0\nAuthor         0\nUser Rating    0\nReviews        0\nPrice          0\nYear           0\nGenre          0\ndtype: int64\n\n\nObserviaciones:\n\nNo hay Missing values"
  },
  {
    "objectID": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#business-understanding",
    "href": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#business-understanding",
    "title": "Exploring Hypothesis Testing: A Series for Beginners 1",
    "section": "",
    "text": "dataset source: https://www.kaggle.com/datasets/sootersaalu/amazon-top-50-bestselling-books-2009-2019/data\n\n\nDatos sobre los 50 libros más vendidos en Amazon de 2009 a 2019.\n\n\n\nVamos a responder a las siguientes preguntas con validez estadística:\n\n¿Los géneros difieren en User Rating?\n¿Los géneros difieren en número de Reviews?\n¿Los géneros difieren en términos de precio?\n\n\n\n\n\n\n\nTip with Title\n\n\n\nThis is an example of a callout with a title."
  },
  {
    "objectID": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#data-understanding",
    "href": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#data-understanding",
    "title": "Exploring Hypothesis Testing: A Series for Beginners 1",
    "section": "",
    "text": "# Import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n\n\n\ndf = pd.read_csv(\"bestsellers with categories.csv\")\ndf.head(10)\n\n\n\n\n\n\n\n\nName\nAuthor\nUser Rating\nReviews\nPrice\nYear\nGenre\n\n\n\n\n0\n10-Day Green Smoothie Cleanse\nJJ Smith\n4.7\n17350\n8\n2016\nNon Fiction\n\n\n1\n11/22/63: A Novel\nStephen King\n4.6\n2052\n22\n2011\nFiction\n\n\n2\n12 Rules for Life: An Antidote to Chaos\nJordan B. Peterson\n4.7\n18979\n15\n2018\nNon Fiction\n\n\n3\n1984 (Signet Classics)\nGeorge Orwell\n4.7\n21424\n6\n2017\nFiction\n\n\n4\n5,000 Awesome Facts (About Everything!) (Natio...\nNational Geographic Kids\n4.8\n7665\n12\n2019\nNon Fiction\n\n\n5\nA Dance with Dragons (A Song of Ice and Fire)\nGeorge R. R. Martin\n4.4\n12643\n11\n2011\nFiction\n\n\n6\nA Game of Thrones / A Clash of Kings / A Storm...\nGeorge R. R. Martin\n4.7\n19735\n30\n2014\nFiction\n\n\n7\nA Gentleman in Moscow: A Novel\nAmor Towles\n4.7\n19699\n15\n2017\nFiction\n\n\n8\nA Higher Loyalty: Truth, Lies, and Leadership\nJames Comey\n4.7\n5983\n3\n2018\nNon Fiction\n\n\n9\nA Man Called Ove: A Novel\nFredrik Backman\n4.6\n23848\n8\n2016\nFiction\n\n\n\n\n\n\n\n\nName\n\nTítulo del libro\nUnidad: texto (categoría)\n\nAuthor\n\nNombre del autor\nUnidad: texto (categoría)\n\nUser Rating\n\nCalificación promedio del libro por los usuarios\nUnidad: número entre 0 y 5 (con decimales)\n\nReviews\n\nNúmero de reseñas\nUnidad: número entero\n\nPrice\n\nPrecio del libro\nUnidad: número entero\n\nYear\n\nAño en el que el libro fue de los más vendidos\nUnidad: año (número entero)\n\nGenre\n\nGénero del libro simplificado (Fiction o Non Fiction)\nUnidad: categorico con dos valores posibles"
  },
  {
    "objectID": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#data-preparation",
    "href": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#data-preparation",
    "title": "Exploring Hypothesis Testing: A Series for Beginners 1",
    "section": "",
    "text": "# comprobamos el tipo de datos de las columnas\ndf.dtypes\n\nName            object\nAuthor          object\nUser Rating    float64\nReviews          int64\nPrice            int64\nYear             int64\nGenre           object\ndtype: object\n\n\n\ncolumnas_categoricas = [\"Genre\", \"Name\", \"Author\"]\ndf[columnas_categoricas] = df[columnas_categoricas].astype(\"category\")\n\n\ndf.dtypes\n\nName           category\nAuthor         category\nUser Rating     float64\nReviews           int64\nPrice             int64\nYear              int64\nGenre          category\ndtype: object\n\n\n\n\n\nComprobar si hay autores o títulos iguales pero escritos diferente.\n\nfrom fuzzywuzzy import fuzz\n\n\n# Función para encontrar nombres de autores similares\ndef encontrar_similares(df, columna):\n    autores = df[columna].unique()\n    duplicados = []\n\n    for i, autor1 in enumerate(autores):\n        for autor2 in autores[i + 1 :]:\n            ratio = fuzz.ratio(autor1, autor2)\n            if ratio &gt; 90:  # Puedes ajustar este umbral según tu criterio\n                duplicados.append((autor1, autor2))\n\n    return duplicados\n\n\n# Encuentra nombres de autores similares\nduplicados = encontrar_similares(df, \"Author\")\n\nprint(\n    \"Nombres de autores que se refieren al mismo autor pero están escritos diferente:\"\n)\nfor dup in duplicados:\n    print(dup)\n\nNombres de autores que se refieren al mismo autor pero están escritos diferente:\n('George R. R. Martin', 'George R.R. Martin')\n('J.K. Rowling', 'J. K. Rowling')\n\n\n\n# Replace the names of the Authors with the correct ones\ndf = df.replace(\"George R. R. Martin\", \"George R.R. Martin\")\ndf = df.replace(\"J. K. Rowling\", \"J.K. Rowling\")\n\n\n# Encuentra nombres de títulos similares\nduplicados = encontrar_similares(df, \"Name\")\n\nprint(\n    \"Nombres de autores que se refieren al mismo autor pero están escritos diferente:\"\n)\nfor dup in duplicados:\n    print(dup)\n\nNombres de autores que se refieren al mismo autor pero están escritos diferente:\n('The 5 Love Languages: The Secret to Love That Lasts', 'The 5 Love Languages: The Secret to Love that Lasts')\n('The Girl Who Played with Fire (Millennium Series)', 'The Girl Who Played with Fire (Millennium)')\n\n\n\n# Replace the names of the Authors with the correct ones\ndf = df.replace(\n    \"The 5 Love Languages: The Secret to Love That Lasts\",\n    \"The 5 Love Languages: The Secret to Love that Lasts\",\n)\ndf = df.replace(\n    \"The Girl Who Played with Fire (Millennium Series)\",\n    \"The Girl Who Played with Fire (Millennium)\",\n)\n\n\ndf\n\n\n\n\n\n\n\n\nName\nAuthor\nUser Rating\nReviews\nPrice\nYear\nGenre\n\n\n\n\n0\n10-Day Green Smoothie Cleanse\nJJ Smith\n4.7\n17350\n8\n2016\nNon Fiction\n\n\n1\n11/22/63: A Novel\nStephen King\n4.6\n2052\n22\n2011\nFiction\n\n\n2\n12 Rules for Life: An Antidote to Chaos\nJordan B. Peterson\n4.7\n18979\n15\n2018\nNon Fiction\n\n\n3\n1984 (Signet Classics)\nGeorge Orwell\n4.7\n21424\n6\n2017\nFiction\n\n\n4\n5,000 Awesome Facts (About Everything!) (Natio...\nNational Geographic Kids\n4.8\n7665\n12\n2019\nNon Fiction\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n545\nWrecking Ball (Diary of a Wimpy Kid Book 14)\nJeff Kinney\n4.9\n9413\n8\n2019\nFiction\n\n\n546\nYou Are a Badass: How to Stop Doubting Your Gr...\nJen Sincero\n4.7\n14331\n8\n2016\nNon Fiction\n\n\n547\nYou Are a Badass: How to Stop Doubting Your Gr...\nJen Sincero\n4.7\n14331\n8\n2017\nNon Fiction\n\n\n548\nYou Are a Badass: How to Stop Doubting Your Gr...\nJen Sincero\n4.7\n14331\n8\n2018\nNon Fiction\n\n\n549\nYou Are a Badass: How to Stop Doubting Your Gr...\nJen Sincero\n4.7\n14331\n8\n2019\nNon Fiction\n\n\n\n\n550 rows × 7 columns\n\n\n\n\n# número de filas duplicadas\ndf.duplicated().sum()\n\n0\n\n\nEs normal no encontrar duplicados en este caso, hay libros que se repiten pero es imposible que coincidan en “Year”. No es un error por si mismo. Pero hay un problema. Las “Reviews” deberían ser las que el libro tenia el año en el que fue de los mas vendidos. En lugar de eso son las del último año. Esto puede deberse a que el autor del dataset no tuvo acceso al historial de las reseñas.\nEs importante tener en cuenta esto para el análisis.\nVamos a utilizar unicamente la muestra más reciente de cada libro.\n\n# todos los libros con el titulo repetido\ndf[df.duplicated(\"Name\")].head(20)\n\n\n\n\n\n\n\n\nName\nAuthor\nUser Rating\nReviews\nPrice\nYear\nGenre\n\n\n\n\n10\nA Man Called Ove: A Novel\nFredrik Backman\n4.6\n23848\n8\n2017\nFiction\n\n\n21\nAll the Light We Cannot See\nAnthony Doerr\n4.6\n36348\n14\n2015\nFiction\n\n\n33\nBecoming\nMichelle Obama\n4.8\n61133\n11\n2019\nNon Fiction\n\n\n36\nBetween the World and Me\nTa-Nehisi Coates\n4.7\n10070\n13\n2016\nNon Fiction\n\n\n41\nBrown Bear, Brown Bear, What Do You See?\nBill Martin Jr.\n4.9\n14344\n5\n2019\nFiction\n\n\n47\nCatching Fire (The Hunger Games)\nSuzanne Collins\n4.7\n22614\n11\n2011\nFiction\n\n\n48\nCatching Fire (The Hunger Games)\nSuzanne Collins\n4.7\n22614\n11\n2012\nFiction\n\n\n51\nCrazy Love: Overwhelmed by a Relentless God\nFrancis Chan\n4.7\n1542\n14\n2010\nNon Fiction\n\n\n52\nCrazy Love: Overwhelmed by a Relentless God\nFrancis Chan\n4.7\n1542\n14\n2011\nNon Fiction\n\n\n57\nCutting for Stone\nAbraham Verghese\n4.6\n4866\n11\n2011\nFiction\n\n\n64\nDear Zoo: A Lift-the-Flap Book\nRod Campbell\n4.8\n10922\n5\n2016\nFiction\n\n\n65\nDear Zoo: A Lift-the-Flap Book\nRod Campbell\n4.8\n10922\n5\n2017\nFiction\n\n\n66\nDear Zoo: A Lift-the-Flap Book\nRod Campbell\n4.8\n10922\n5\n2018\nFiction\n\n\n70\nDiagnostic and Statistical Manual of Mental Di...\nAmerican Psychiatric Association\n4.5\n6679\n105\n2014\nNon Fiction\n\n\n76\nDivergent\nVeronica Roth\n4.6\n27098\n15\n2014\nFiction\n\n\n84\nDog Man: Brawl of the Wild: From the Creator o...\nDav Pilkey\n4.9\n7235\n4\n2019\nFiction\n\n\n94\nEat to Live: The Amazing Nutrient-Rich Program...\nJoel Fuhrman MD\n4.5\n6346\n9\n2012\nNon Fiction\n\n\n98\nEducated: A Memoir\nTara Westover\n4.7\n28729\n15\n2019\nNon Fiction\n\n\n101\nFahrenheit 451\nRay Bradbury\n4.6\n10721\n8\n2018\nFiction\n\n\n107\nFifty Shades of Grey: Book One of the Fifty Sh...\nE L James\n3.8\n47265\n14\n2013\nFiction\n\n\n\n\n\n\n\n\n# Drop duplicates\nbestsellers = df.drop_duplicates(subset=\"Name\", keep=\"last\")\nbestsellers\n\n\n\n\n\n\n\n\nName\nAuthor\nUser Rating\nReviews\nPrice\nYear\nGenre\n\n\n\n\n0\n10-Day Green Smoothie Cleanse\nJJ Smith\n4.7\n17350\n8\n2016\nNon Fiction\n\n\n1\n11/22/63: A Novel\nStephen King\n4.6\n2052\n22\n2011\nFiction\n\n\n2\n12 Rules for Life: An Antidote to Chaos\nJordan B. Peterson\n4.7\n18979\n15\n2018\nNon Fiction\n\n\n3\n1984 (Signet Classics)\nGeorge Orwell\n4.7\n21424\n6\n2017\nFiction\n\n\n4\n5,000 Awesome Facts (About Everything!) (Natio...\nNational Geographic Kids\n4.8\n7665\n12\n2019\nNon Fiction\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n538\nWinter of the World: Book Two of the Century T...\nKen Follett\n4.5\n10760\n15\n2012\nFiction\n\n\n539\nWomen Food and God: An Unexpected Path to Almo...\nGeneen Roth\n4.2\n1302\n11\n2010\nNon Fiction\n\n\n544\nWonder\nR. J. Palacio\n4.8\n21625\n9\n2017\nFiction\n\n\n545\nWrecking Ball (Diary of a Wimpy Kid Book 14)\nJeff Kinney\n4.9\n9413\n8\n2019\nFiction\n\n\n549\nYou Are a Badass: How to Stop Doubting Your Gr...\nJen Sincero\n4.7\n14331\n8\n2019\nNon Fiction\n\n\n\n\n349 rows × 7 columns\n\n\n\nResumen: - Hemos corregido los errores ortográficos de los títulos y autores. - Hemos seleccionado las muestras más recientes de cada libro.\nHemos reducido el tamaño del dataset de 550 a 349 muestras.\n\n\n\n\n\nIQR: El rango intercuartil (IQR) es la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1). Los valores que caen por debajo de Q1 - 1.5 * IQR o por encima de Q3 + 1.5 * IQR se consideran outliers.\nLos valores fuera del de este rango, son los que se representa como puntos en los bloxpots.\n\nimport plotly.express as px\n\nselected_columns = [\"Reviews\", \"Price\"]\n\nfor column in selected_columns:\n    fig = px.box(df, x=column, title=f\"Boxplot of {column}\")\n    fig.update_layout(title_x=0.5)  # Centra el título\n    fig.show()\n\n\n                                                \n\n\n\n                                                \n\n\nObservaciones:\n\nage: no se detectan outliers\nBMI: existen outliers, personas con una alta obesidad\ncharges: existen outliers, personas con cargos muy altos al seguro\n\n\n\n\n\n\nbestsellers.describe()\n\n\n\n\n\n\n\n\nUser Rating\nReviews\nPrice\nYear\n\n\n\n\ncount\n349.000000\n349.000000\n349.000000\n349.000000\n\n\nmean\n4.608596\n9811.922636\n12.962751\n2014.128940\n\n\nstd\n0.227266\n10899.783863\n10.011562\n3.377239\n\n\nmin\n3.300000\n37.000000\n0.000000\n2009.000000\n\n\n25%\n4.500000\n3428.000000\n8.000000\n2011.000000\n\n\n50%\n4.600000\n6310.000000\n11.000000\n2014.000000\n\n\n75%\n4.800000\n11550.000000\n16.000000\n2017.000000\n\n\nmax\n4.900000\n87841.000000\n105.000000\n2019.000000\n\n\n\n\n\n\n\nVariables númericas\n\nselected_columns = [\"User Rating\", \"Reviews\", \"Price\"]\n\n# Calcular la varianza de cada columna\nvariances = bestsellers[selected_columns].var()\n\n# Definir un umbral para la varianza\nthreshold = 0.1\n\n# Identificar las columnas con varianza cercana a cero o muy pequeña\nzero_variance_cols = variances[variances &lt;= threshold].index\n\nprint(\"Columnas con Zero & Near Zero Variance:\")\nprint(zero_variance_cols)\n\nColumnas con Zero & Near Zero Variance:\nIndex(['User Rating'], dtype='object')\n\n\nVariables categoricas. No tiene sentido en este analisis en este caso.\nObserviaciones:\n\nNo se detectan variables con Zero & Near Zero Variance\n\n\n\n\n\nbestsellers.isnull().sum()\n\nName           0\nAuthor         0\nUser Rating    0\nReviews        0\nPrice          0\nYear           0\nGenre          0\ndtype: int64\n\n\nObserviaciones:\n\nNo hay Missing values"
  },
  {
    "objectID": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#los-géneros-difieren-en-user-rating",
    "href": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#los-géneros-difieren-en-user-rating",
    "title": "Exploring Hypothesis Testing: A Series for Beginners 1",
    "section": "¿Los géneros difieren en User Rating?",
    "text": "¿Los géneros difieren en User Rating?\nVamos a crear una variable para cada grupo de interes y representarlos gráficamente.\n\nfiction_bestsellers = bestsellers[bestsellers[\"Genre\"] == \"Fiction\"]\nnonfiction_bestsellers = bestsellers[bestsellers[\"Genre\"] == \"Non Fiction\"]\n\n\nsns.kdeplot(fiction_bestsellers[\"User Rating\"], fill=True, color=\"r\")\nsns.kdeplot(nonfiction_bestsellers[\"User Rating\"], fill=True, color=\"b\")\nplt.legend([\"Fiction\", \"Non Fiction\"])\nplt.xlabel(\"User Rating\")\nplt.ylabel(\"Density\")\nplt.show()\n\n\n\n\n\n# Calcular el coeficiente de asimetría\nskewness = stats.skew(bestsellers[\"User Rating\"])\nprint(\"Coeficiente de asimetría:\", skewness)\n\nif skewness &gt; 0:\n    print(\"La distribución está positivamente sesgada.\")\nelif skewness &lt; 0:\n    print(\"La distribución está negativamente sesgada.\")\nelse:\n    print(\"La distribución es simétrica.\")\n\nCoeficiente de asimetría: -1.521358275451138\nLa distribución está negativamente sesgada.\n\n\nNúmero de observaciones para cada grupo:\n\nbestsellers[\"Genre\"].value_counts()\n\nGenre\nNon Fiction    190\nFiction        159\nName: count, dtype: int64\n\n\nRealizamos un test de normalidad para cada grupo:\n\nfrom scipy import stats\n\n\ndef shapiro_test(data, alpha=0.05):\n    \"\"\"\n    Realiza la prueba de Shapiro-Wilk para verificar la normalidad de los datos.\n\n    Parameters:\n    data (array-like): Los datos a analizar.\n    alpha (float): Nivel de significancia.\n\n    Returns:\n    str: El resultado de la prueba.\n    \"\"\"\n    statistic, p_value = stats.shapiro(data)\n\n    if p_value &lt; alpha:\n        return (\n            \"Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\"\n        )\n    else:\n        return \"Fallamos al rechazar la hipótesis nula. Los datos pueden considerarse normalmente distribuidos.\"\n\n\nresult_fiction = shapiro_test(fiction_bestsellers[\"User Rating\"])\nresult_nonfiction = shapiro_test(nonfiction_bestsellers[\"User Rating\"])\n\nprint(\"Para bestsellers de ficción:\", result_fiction)\nprint(\"Para bestsellers de no ficción:\", result_nonfiction)\n\nPara bestsellers de ficción: Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\nPara bestsellers de no ficción: Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\n\n\nEstudiemos la relación entre las varianzas de cada grupo.\n\n# Realiza el Test de Levene\nstatistic, p_value = stats.levene(\n    fiction_bestsellers[\"User Rating\"], nonfiction_bestsellers[\"User Rating\"]\n)\n\n# Nivel de significancia\nalpha = 0.05\n\n# Comprueba la significancia\nif p_value &lt; alpha:\n    print(\"Rechazamos la hipótesis nula. Las varianzas no son similares\")\nelse:\n    print(\"Fallamos al rechazar la hipótesis nula. Las varianzas son similares\")\n\nRechazamos la hipótesis nula. Las varianzas no son similares\n\n\n\n# varianza de los grupos\nbestsellers.groupby([\"Genre\"])[\"User Rating\"].var()\n\nGenre\nFiction        0.075720\nNon Fiction    0.031736\nName: User Rating, dtype: float64\n\n\n\n1. Seleccionamos la hipotesis y el nivel de significancia\nH0: El “User Rating” de los libros de ficción es igual que el de los libros de no ficción\nHa: El “User Rating” de los libros de ficción es diferente que el de los libros de no ficción\nalpha = 0.05\n\n\n2. Identificamos el tipo de test\nDeseamos comparar las medias de dos grupos de nuestra Sample. Por lo que un 2-Sample t-Test parece lo adecuado. Lo primero es ver si se cumplen los requisitos del test.\n\n2.1 Requisitos del test\n[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions Page: 48 Section: 2-Sample t-Tests] - Tenemos un Sample representativo de la población? Si. - Los datos son continuos? - En este contexto, los “User Rating” que van de 0 a 5 con un único decimal pueden considerarse como datos continuos. Sim embargo, observando las gráficas, vemos que la mayoría de los valores se encuetran en un intervalor muy pequeño (mayores a 4.0). Esto dificulta el poder considerarlo continuos. - Las muestras siguen una distribución normal o hay más de 15 observaciones - No, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema del límite central podemos renunciar al supuesto de normalidad. - Los grupos son independientes? Si. - Las varianzas son iguales (o al menos similares)? - No.\nPor la falta de continuidad en los datos, vamos a realizar un test no paramétrico Mann-Whitney.\n[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions Page: 341 Section: Analyzing Likert Scale Data]\nPara realizar el test vamos a usar scipy.stats.mannwhitneyu\n\n# Realiza el test de Mann-Whitney\nstatistic, p_value = stats.mannwhitneyu(\n    nonfiction_bestsellers[\"User Rating\"], fiction_bestsellers[\"User Rating\"]\n)\n\n# Imprime los resultados\nprint(\"Valor p:\", p_value)\n\n# Comprueba la significancia\nalpha = 0.05  # Nivel de significancia\nif p_value &lt; alpha:\n    print(\n        \"Rechazamos la hipótesis nula. Hay diferencias significativas entre los grupos.\"\n    )\nelse:\n    print(\n        \"Fallamos al rechazar la hipótesis nula. No hay diferencias significativas entre los grupos.\"\n    )\n\nValor p: 0.019840907319029977\nRechazamos la hipótesis nula. Hay diferencias significativas entre los grupos."
  },
  {
    "objectID": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#los-géneros-difieren-en-número-de-reviews",
    "href": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#los-géneros-difieren-en-número-de-reviews",
    "title": "Exploring Hypothesis Testing: A Series for Beginners 1",
    "section": "¿Los géneros difieren en número de Reviews?",
    "text": "¿Los géneros difieren en número de Reviews?\nRepresentamos gráficamente los grupos de interés.\n\nsns.kdeplot(fiction_bestsellers[\"Reviews\"], fill=True, color=\"r\")\nsns.kdeplot(nonfiction_bestsellers[\"Reviews\"], fill=True, color=\"b\")\nplt.legend([\"Fiction\", \"Non Fiction\"])\nplt.xlabel(\"User Rating\")\nplt.ylabel(\"Density\")\nplt.show()\n\n\n\n\n\n# Calcular el coeficiente de asimetría\nskewness = stats.skew(bestsellers[\"Reviews\"])\nprint(\"Coeficiente de asimetría:\", skewness)\n\nif skewness &gt; 0:\n    print(\"La distribución está positivamente sesgada.\")\nelif skewness &lt; 0:\n    print(\"La distribución está negativamente sesgada.\")\nelse:\n    print(\"La distribución es simétrica.\")\n\nCoeficiente de asimetría: 3.119812029552558\nLa distribución está positivamente sesgada.\n\n\nNúmero de observaciones para cada grupo:\n\nbestsellers[\"Genre\"].value_counts()\n\nGenre\nNon Fiction    190\nFiction        159\nName: count, dtype: int64\n\n\nRealizamos un test de normalidad para cada grupo:\n\nfrom scipy import stats\n\n\ndef shapiro_test(data, alpha=0.05):\n    \"\"\"\n    Realiza la prueba de Shapiro-Wilk para verificar la normalidad de los datos.\n\n    Parameters:\n    data (array-like): Los datos a analizar.\n    alpha (float): Nivel de significancia.\n\n    Returns:\n    str: El resultado de la prueba.\n    \"\"\"\n    statistic, p_value = stats.shapiro(data)\n\n    if p_value &lt; alpha:\n        return (\n            \"Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\"\n        )\n    else:\n        return \"Fallamos al rechazar la hipótesis nula. Los datos pueden considerarse normalmente distribuidos.\"\n\n\nresult_fiction = shapiro_test(fiction_bestsellers[\"Reviews\"])\nresult_nonfiction = shapiro_test(nonfiction_bestsellers[\"Reviews\"])\n\nprint(\"Para bestsellers de ficción:\", result_fiction)\nprint(\"Para bestsellers de no ficción:\", result_nonfiction)\n\nPara bestsellers de ficción: Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\nPara bestsellers de no ficción: Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\n\n\nEstudiemos la relación entre las varianzas de cada grupo.\n\n# varianza de los grupos\nbestsellers.groupby([\"Genre\"])[\"Reviews\"].var()\n\nGenre\nFiction        1.781185e+08\nNon Fiction    5.265203e+07\nName: Reviews, dtype: float64\n\n\n\n# Realiza el Test de Levene\nstatistic, p_value = stats.levene(\n    fiction_bestsellers[\"User Rating\"], nonfiction_bestsellers[\"User Rating\"]\n)\n\n# Nivel de significancia\nalpha = 0.05\n\n# Comprueba la significancia\nif p_value &lt; alpha:\n    print(\"Rechazamos la hipótesis nula. Las varianzas no son similares\")\nelse:\n    print(\"Fallamos al rechazar la hipótesis nula. Las varianzas son similares\")\n\nRechazamos la hipótesis nula. Las varianzas no son similares\n\n\n\n1. Seleccionamos la hipotesis y el nivel de significancia\nH0: El número de Reviews medio de los libros de ficción es igual que el de los libros de no ficción\nHa: El número de Reviews medio de los libros de ficción es diferente que el de los libros de no ficción\nalpha = 0.05\n\n\n2. Identificamos el tipo de test\nDeseamos comparar las medias de dos grupos de nuestra Sample. Por lo que un 2-Sample t-Test parece lo adecuado. Lo primero es ver si se cumplen los requisitos del test.\n\n2.1 Requisitos del test\n[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions Page: 48 Section: 2-Sample t-Tests] - Tenemos un Sample representativo de la población? Si. - Los datos son continuos? Si. - Las muestras siguen una distribución normal o hay más de 15 observaciones - No, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema del límite central podemos renunciar al supuesto de normalidad. - Los grupos son independientes? Si. - Las varianzas son iguales (o al menos similares)? - No.\nLas varianzas no son similares y su relación es de más del doble. Vamos a reliazar un test tipo Welch’s t-test.\nPara realizar el test vamos a usar scipy.stats.ttest_ind. Para realizar este test, es necesario definir el parametro equal_varbool como False.\n\n# Realiza el test t de Welch (equal_var=False)\nstatistic, p_value = stats.ttest_ind(\n    nonfiction_bestsellers[\"Reviews\"], fiction_bestsellers[\"Reviews\"], equal_var=False\n)\n\n# Imprime los resultados\nprint(\"Valor p:\", p_value)\n\n# Comprueba la significancia\nalpha = 0.05  # Nivel de significancia\nif p_value &lt; alpha:\n    print(\n        \"Rechazamos la hipótesis nula: Hay diferencias significativas entre los grupos.\"\n    )\nelse:\n    print(\n        \"No podemos rechazar la hipótesis nula: No hay diferencias significativas entre los grupos.\"\n    )\n\nValor p: 4.7012426165976585e-07\nRechazamos la hipótesis nula: Hay diferencias significativas entre los grupos.\n\n\nLos libros del género de ficción obtienen más Reviews que los libros de no ficción."
  },
  {
    "objectID": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#los-géneros-difieren-en-términos-de-price",
    "href": "posts/2023-10-16-bestsellers_hypothesis_testing/bestsellers_with_categories_hypothesis_testing.html#los-géneros-difieren-en-términos-de-price",
    "title": "Exploring Hypothesis Testing: A Series for Beginners 1",
    "section": "¿Los géneros difieren en términos de Price?",
    "text": "¿Los géneros difieren en términos de Price?\nRepresentamos gráficamente los datos.\n\nsns.kdeplot(fiction_bestsellers[\"Price\"], fill=True, color=\"r\")\nsns.kdeplot(nonfiction_bestsellers[\"Price\"], fill=True, color=\"b\")\nplt.legend([\"Fiction\", \"Non Fiction\"])\nplt.xlabel(\"User Rating\")\nplt.ylabel(\"Density\")\nplt.show()\n\n\n\n\n\n# Calcular el coeficiente de asimetría\nskewness = stats.skew(bestsellers[\"Price\"])\nprint(\"Coeficiente de asimetría:\", skewness)\n\nif skewness &gt; 0:\n    print(\"La distribución está positivamente sesgada.\")\nelif skewness &lt; 0:\n    print(\"La distribución está negativamente sesgada.\")\nelse:\n    print(\"La distribución es simétrica.\")\n\nCoeficiente de asimetría: 4.059768474746167\nLa distribución está positivamente sesgada.\n\n\nRealizamos un test de normalidad para cada grupo:\n\nfrom scipy import stats\n\n\ndef shapiro_test(data, alpha=0.05):\n    \"\"\"\n    Realiza la prueba de Shapiro-Wilk para verificar la normalidad de los datos.\n\n    Parameters:\n    data (array-like): Los datos a analizar.\n    alpha (float): Nivel de significancia.\n\n    Returns:\n    str: El resultado de la prueba.\n    \"\"\"\n    statistic, p_value = stats.shapiro(data)\n\n    if p_value &lt; alpha:\n        return (\n            \"Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\"\n        )\n    else:\n        return \"Fallamos al rechazar la hipótesis nula. Los datos pueden considerarse normalmente distribuidos.\"\n\n\nresult_fiction = shapiro_test(fiction_bestsellers[\"Price\"])\nresult_nonfiction = shapiro_test(nonfiction_bestsellers[\"Price\"])\n\nprint(\"Para bestsellers de ficción:\", result_fiction)\nprint(\"Para bestsellers de no ficción:\", result_nonfiction)\n\nPara bestsellers de ficción: Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\nPara bestsellers de no ficción: Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\n\n\nEstudiemos la relación entre las varianzas de cada grupo.\n\n# Realiza el Test de Levene\nstatistic, p_value = stats.levene(\n    fiction_bestsellers[\"Price\"], nonfiction_bestsellers[\"Price\"]\n)\n\n# Nivel de significancia\nalpha = 0.05\n\n# Comprueba la significancia\nif p_value &lt; alpha:\n    print(\"Rechazamos la hipótesis nula. Las varianzas no son similares\")\nelse:\n    print(\"Fallamos al rechazar la hipótesis nula. Las varianzas son similares\")\n\nFallamos al rechazar la hipótesis nula. Las varianzas son similares\n\n\n\n# varianza de los grupos\nbestsellers.groupby([\"Genre\"])[\"Price\"].var()\n\nGenre\nFiction         91.521376\nNon Fiction    107.024673\nName: Price, dtype: float64\n\n\n\n1. Seleccionamos la hipotesis y el nivel de significancia\nH0: El precio medio de los libros de ficción es igual que el de los libros de no ficción\nHa: El precio medio de los libros de ficción es diferente que el de los libros de no ficción\nalpha = 0.05\n\n\n2. Identificamos el tipo de test\nDeseamos comparar las medias de dos grupos de nuestra Sample. Por lo que un 2-Sample t-Test parece lo adecuado. Lo primero es ver si se cumplen los requisitos del test.\n\n2.1 Requisitos del test\n[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions Page: 48 Section: 2-Sample t-Tests] - Tenemos un Sample representativo de la población? Si. - Los datos son continuos? Si. - Las muestras siguen una distribución normal o hay más de 15 observaciones - No, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema del límite central podemos renunciar al supuesto de normalidad. - Los grupos son independientes? Si. - Las varianzas son iguales (o al menos similares)? Si.\nSe cumplen los requisitos para realizar un 2-Sample t-Test.\nPara realizar el test vamos a usar scipy.stats.ttest_ind.\n\n# Realiza el test t\nstatistic, p_value = stats.ttest_ind(\n    nonfiction_bestsellers[\"Price\"], fiction_bestsellers[\"Price\"]\n)\n\n# Imprime los resultados\nprint(\"Valor p:\", p_value)\n\n# Comprueba la significancia\nalpha = 0.05  # Nivel de significancia\nif p_value &lt; alpha:\n    print(\n        \"Rechazamos la hipótesis nula: Hay diferencias significativas entre los grupos.\"\n    )\nelse:\n    print(\n        \"No podemos rechazar la hipótesis nula: No hay diferencias significativas entre los grupos.\"\n    )\n\nValor p: 0.16615124881617802\nNo podemos rechazar la hipótesis nula: No hay diferencias significativas entre los grupos.\n\n\nEl precio no es dependiente del género."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "¡Hola! Soy Micael, un entusiasta de la tecnología y un devorador de libros empedernido. Cuando no estoy enredando con líneas de código, me sumerjo en aventuras literarias que me transportan a mundos imaginarios. Apasionado por el aprendizaje constante, combino la lógica de la programación con la creatividad de las historias. Mi mantra: ‘Cada día es una página en blanco, y yo soy el autor de mi propia narrativa’. Únete a mí en este viaje donde la curiosidad es la brújula y el conocimiento es el tesoro que perseguimos."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "Exploring Hypothesis Testing: A Series for Beginners 1\n\n\n\n\n\n\n\nEDA\n\n\nhypothesis-testing\n\n\n\n\nA series of posts exploring hypothesis testing for beginners.\n\n\n\n\n\n\nOct 16, 2023\n\n\nMicael García\n\n\n\n\n\n\nNo matching items"
  }
]