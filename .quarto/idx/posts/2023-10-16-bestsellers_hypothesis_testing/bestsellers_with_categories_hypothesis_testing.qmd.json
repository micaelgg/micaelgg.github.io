{"title":"Exploring Hypothesis Testing: A Series for Beginners","markdown":{"yaml":{"title":"Exploring Hypothesis Testing: A Series for Beginners","jupyter":"python3"},"headingText":"2. Data Understanding","containsRefs":false,"markdown":"\n\n\n\n### 2.1 Donwload data from Kaggle\n\n```{python}\n# Import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n```\n\nDownload dataset\n\n```{python}\nfrom kaggle import KaggleApi\nimport os\n\n# Nombre del archivo del dataset en Kaggle\ndataset_name = \"bestsellers with categories.csv\"\n# ID del dataset en Kaggle\ndataset_id = \"sootersaalu/amazon-top-50-bestselling-books-2009-2019/\"\n\n# Directorio de destino\ndownload_path = \"./data/\"\n\n# Verificar si el archivo ya existe en la carpeta de destino\nlist_of_files = os.listdir(download_path)\nif any(dataset_name in filename for filename in list_of_files):\n    print(\"El archivo ya existe \" + download_path)\nelse:\n    # Autenticar con la API de Kaggle\n    api = KaggleApi()\n    api.authenticate()\n\n    # Descargar el dataset\n    api.dataset_download_files(dataset_id, path=download_path, unzip=True)\n```\n\n### 2.2 Data description\n\n```{python}\ndf = pd.read_csv(download_path + dataset_name)\ndf.head(30)\n```\n\n- Name\n  - Título del libro\n  - Unidad: texto (categoría)\n- Author\n  - Nombre del autor\n  - Unidad: texto (categoría)\n- User Rating\n  - Calificación promedio del libro por los usuarios\n  - Unidad: número entre 0 y 5 (con decimales)\n- Reviews\n  - Número de reseñas\n  - Unidad: número entero\n- Price\n  - Precio del libro\n  - Unidad: número entero\n- Year\n  - Año en el que el libro fue de los más vendidos\n  - Unidad: año (número entero)\n- Genre\n  - Género del libro simplificado (Fiction o Non Fiction)\n  - Unidad: categorico con dos valores posibles\n\n## 3. Data preparation\n\n### 3.1 Typecasting\n\n## 1. Business Understanding\n\ndataset source: https://www.kaggle.com/datasets/sootersaalu/amazon-top-50-bestselling-books-2009-2019/data\n\n### Context\nDatos sobre los 50 libros más vendidos en Amazon de 2009 a 2019. \n\n### Hypothesis to Test\n\nVamos a responder a las siguientes preguntas con validez estadística:\n\n- ¿Los géneros difieren en User Rating?\n- ¿Los géneros difieren en número de Reviews?\n- ¿Los géneros difieren en términos de precio?\n\n```{python}\n# comprobamos el tipo de datos de las columnas\ndf.dtypes\n```\n\n```{python}\ncolumnas_categoricas = [\"Genre\", \"Name\", \"Author\"]\ndf[columnas_categoricas] = df[columnas_categoricas].astype(\"category\")\n```\n\n```{python}\ndf.dtypes\n```\n\n### 3.2 Handling Duplicates\n\nComprobar si hay autores o títulos iguales pero escritos diferente.\n\n```{python}\nfrom fuzzywuzzy import fuzz\n\n\n# Función para encontrar nombres de autores similares\ndef encontrar_similares(df, columna):\n    autores = df[columna].unique()\n    duplicados = []\n\n    for i, autor1 in enumerate(autores):\n        for autor2 in autores[i + 1 :]:\n            ratio = fuzz.ratio(autor1, autor2)\n            if ratio > 90:  # Puedes ajustar este umbral según tu criterio\n                duplicados.append((autor1, autor2))\n\n    return duplicados\n\n\n```\n\n```{python}\n# Encuentra nombres de autores similares\nduplicados = encontrar_similares(df, \"Author\")\n\nprint(\n    \"Nombres de autores que se refieren al mismo autor pero están escritos diferente:\"\n)\nfor dup in duplicados:\n    print(dup)\n```\n\n```{python}\n# Replace the names of the Authors with the correct ones\ndf = df.replace(\"George R. R. Martin\", \"George R.R. Martin\")\ndf = df.replace(\"J. K. Rowling\", \"J.K. Rowling\")\n```\n\n```{python}\n# Encuentra nombres de títulos similares\nduplicados = encontrar_similares(df, \"Name\")\n\nprint(\n    \"Nombres de autores que se refieren al mismo autor pero están escritos diferente:\"\n)\nfor dup in duplicados:\n    print(dup)\n```\n\n```{python}\n# Replace the names of the Authors with the correct ones\ndf = df.replace(\n    \"The 5 Love Languages: The Secret to Love That Lasts\",\n    \"The 5 Love Languages: The Secret to Love that Lasts\",\n)\ndf = df.replace(\n    \"The Girl Who Played with Fire (Millennium Series)\",\n    \"The Girl Who Played with Fire (Millennium)\",\n)\n```\n\n```{python}\ndf\n```\n\n```{python}\n# número de filas duplicadas\ndf.duplicated().sum()\n```\n\nEs normal no encontrar duplicados en este caso, hay libros que se repiten pero es imposible que coincidan en \"Year\". No es un error por si mismo. Pero hay un problema. Las \"Reviews\" deberían ser las que el libro tenia el año en el que fue de los mas vendidos. En lugar de eso son las del último año. Esto puede deberse a que el autor del dataset no tuvo acceso al historial de las reseñas.\n\nEs importante tener en cuenta esto para el análisis.\n\nVamos a utilizar unicamente la muestra más reciente de cada libro.\n\n```{python}\n# todos los libros con el titulo repetido\ndf[df.duplicated(\"Name\")].head(20)\n```\n\n```{python}\n# Drop duplicates\nbestsellers = df.drop_duplicates(subset=\"Name\", keep=\"last\")\nbestsellers\n```\n\nResumen:\n- Hemos corregido los errores ortográficos de los títulos y autores.\n- Hemos seleccionado las muestras más recientes de cada libro.\n\nHemos reducido el tamaño del dataset de 550 a 349 muestras.\n\n### 3.3 Outlier Analysis\n\n#### 3.3.2 Usando boxplot y IQR \nIQR: El rango intercuartil (IQR) es la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1). Los valores que caen por debajo de Q1 - 1.5 * IQR o por encima de Q3 + 1.5 * IQR se consideran outliers.\n\nLos valores fuera del de este rango, son los que se representa como puntos en los bloxpots.\n\n```{python}\nimport plotly.express as px\n\nselected_columns = [\"Reviews\", \"Price\"]\n\nfor column in selected_columns:\n    fig = px.box(df, x=column, title=f\"Boxplot of {column}\")\n    fig.update_layout(title_x=0.5)  # Centra el título\n    fig.show()\n```\n\nObservaciones:\n\n- age: no se detectan outliers\n- BMI: existen outliers, personas con una alta obesidad\n- charges: existen outliers, personas con cargos muy altos al seguro\n\n### 3.4 Zero & Near Zero Variance Features\n\n```{python}\nbestsellers.describe()\n```\n\nVariables númericas\n\n```{python}\nselected_columns = [\"User Rating\", \"Reviews\", \"Price\"]\n\n# Calcular la varianza de cada columna\nvariances = bestsellers[selected_columns].var()\n\n# Definir un umbral para la varianza\nthreshold = 0.1\n\n# Identificar las columnas con varianza cercana a cero o muy pequeña\nzero_variance_cols = variances[variances <= threshold].index\n\nprint(\"Columnas con Zero & Near Zero Variance:\")\nprint(zero_variance_cols)\n```\n\nVariables categoricas. No tiene sentido en este analisis en este caso.\n\nObserviaciones:\n\n- No se detectan variables con Zero & Near Zero Variance\n\n### 3.5 Missing values\n\n```{python}\nbestsellers.isnull().sum()\n```\n\nObserviaciones:\n\n- No hay Missing values\n\n# 4. Hipothesis Testing\n\nVamos a responder a las siguientes preguntas con validez estadística:\n- ¿Los géneros difieren en User Rating?\n- ¿Los géneros difieren en número de Reviews?\n- ¿Los géneros difieren en términos de precio?\n\n## ¿Los géneros difieren en User Rating?\n\nVamos a crear una variable para cada grupo de interes y representarlos gráficamente.\n\n```{python}\nfiction_bestsellers = bestsellers[bestsellers[\"Genre\"] == \"Fiction\"]\nnonfiction_bestsellers = bestsellers[bestsellers[\"Genre\"] == \"Non Fiction\"]\n```\n\n```{python}\nsns.kdeplot(fiction_bestsellers[\"User Rating\"], fill=True, color=\"r\")\nsns.kdeplot(nonfiction_bestsellers[\"User Rating\"], fill=True, color=\"b\")\nplt.legend([\"Fiction\", \"Non Fiction\"])\nplt.xlabel(\"User Rating\")\nplt.ylabel(\"Density\")\nplt.show()\n```\n\n```{python}\n# Calcular el coeficiente de asimetría\nskewness = stats.skew(bestsellers[\"User Rating\"])\nprint(\"Coeficiente de asimetría:\", skewness)\n\nif skewness > 0:\n    print(\"La distribución está positivamente sesgada.\")\nelif skewness < 0:\n    print(\"La distribución está negativamente sesgada.\")\nelse:\n    print(\"La distribución es simétrica.\")\n```\n\nNúmero de observaciones para cada grupo:\n\n```{python}\nbestsellers[\"Genre\"].value_counts()\n```\n\nRealizamos un test de normalidad para cada grupo:\n\n```{python}\nfrom scipy import stats\n\n\ndef shapiro_test(data, alpha=0.05):\n    \"\"\"\n    Realiza la prueba de Shapiro-Wilk para verificar la normalidad de los datos.\n\n    Parameters:\n    data (array-like): Los datos a analizar.\n    alpha (float): Nivel de significancia.\n\n    Returns:\n    str: El resultado de la prueba.\n    \"\"\"\n    statistic, p_value = stats.shapiro(data)\n\n    if p_value < alpha:\n        return (\n            \"Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\"\n        )\n    else:\n        return \"Fallamos al rechazar la hipótesis nula. Los datos pueden considerarse normalmente distribuidos.\"\n\n\nresult_fiction = shapiro_test(fiction_bestsellers[\"User Rating\"])\nresult_nonfiction = shapiro_test(nonfiction_bestsellers[\"User Rating\"])\n\nprint(\"Para bestsellers de ficción:\", result_fiction)\nprint(\"Para bestsellers de no ficción:\", result_nonfiction)\n```\n\nEstudiemos la relación entre las varianzas de cada grupo.\n\n```{python}\n# Realiza el Test de Levene\nstatistic, p_value = stats.levene(\n    fiction_bestsellers[\"User Rating\"], nonfiction_bestsellers[\"User Rating\"]\n)\n\n# Nivel de significancia\nalpha = 0.05\n\n# Comprueba la significancia\nif p_value < alpha:\n    print(\"Rechazamos la hipótesis nula. Las varianzas no son similares\")\nelse:\n    print(\"Fallamos al rechazar la hipótesis nula. Las varianzas son similares\")\n```\n\n```{python}\n# varianza de los grupos\nbestsellers.groupby([\"Genre\"])[\"User Rating\"].var()\n```\n\n### 1. Seleccionamos la hipotesis y el nivel de significancia\n\nH0: El \"User Rating\" de los libros de ficción es igual que el de los libros de no ficción\n\nHa: El \"User Rating\" de los libros de ficción es diferente que el de los libros de no ficción\n\nalpha = 0.05\n\n### 2. Identificamos el tipo de test\n\nDeseamos comparar las medias de dos grupos de nuestra Sample. Por lo que un 2-Sample t-Test parece lo adecuado. Lo primero es ver si se cumplen los requisitos del test.\n\n#### 2.1 Requisitos del test\n[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 48\nSection: 2-Sample t-Tests]\n- Tenemos un Sample representativo de la población? Si.\n- Los datos son continuos? \n  - En este contexto, los \"User Rating\" que van de 0 a 5 con un único decimal pueden considerarse como datos continuos. Sim embargo, observando las gráficas, vemos que la mayoría de los valores se encuetran en un intervalor muy pequeño (mayores a 4.0). Esto dificulta el poder considerarlo continuos.\n- Las muestras siguen una distribución normal o hay más de 15 observaciones\n  - No, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema del límite central podemos renunciar al supuesto de normalidad.\n- Los grupos son independientes? Si.\n- Las varianzas son iguales (o al menos similares)?\n  - No.\n\n\nPor la falta de continuidad en los datos, vamos a realizar un **test no paramétrico Mann-Whitney**.\n\n[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 341\nSection: Analyzing Likert Scale Data]\n\nPara realizar el test vamos a usar [scipy.stats.mannwhitneyu](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html)\n\n```{python}\n# Realiza el test de Mann-Whitney\nstatistic, p_value = stats.mannwhitneyu(\n    nonfiction_bestsellers[\"User Rating\"], fiction_bestsellers[\"User Rating\"]\n)\n\n# Imprime los resultados\nprint(\"Valor p:\", p_value)\n\n# Comprueba la significancia\nalpha = 0.05  # Nivel de significancia\nif p_value < alpha:\n    print(\n        \"Rechazamos la hipótesis nula. Hay diferencias significativas entre los grupos.\"\n    )\nelse:\n    print(\n        \"Fallamos al rechazar la hipótesis nula. No hay diferencias significativas entre los grupos.\"\n    )\n```\n\n## ¿Los géneros difieren en número de Reviews?\n\nRepresentamos gráficamente los grupos de interés.\n\n```{python}\nsns.kdeplot(fiction_bestsellers[\"Reviews\"], fill=True, color=\"r\")\nsns.kdeplot(nonfiction_bestsellers[\"Reviews\"], fill=True, color=\"b\")\nplt.legend([\"Fiction\", \"Non Fiction\"])\nplt.xlabel(\"User Rating\")\nplt.ylabel(\"Density\")\nplt.show()\n```\n\n```{python}\n# Calcular el coeficiente de asimetría\nskewness = stats.skew(bestsellers[\"Reviews\"])\nprint(\"Coeficiente de asimetría:\", skewness)\n\nif skewness > 0:\n    print(\"La distribución está positivamente sesgada.\")\nelif skewness < 0:\n    print(\"La distribución está negativamente sesgada.\")\nelse:\n    print(\"La distribución es simétrica.\")\n```\n\nNúmero de observaciones para cada grupo:\n\n```{python}\nbestsellers[\"Genre\"].value_counts()\n```\n\nRealizamos un test de normalidad para cada grupo:\n\n```{python}\nfrom scipy import stats\n\n\ndef shapiro_test(data, alpha=0.05):\n    \"\"\"\n    Realiza la prueba de Shapiro-Wilk para verificar la normalidad de los datos.\n\n    Parameters:\n    data (array-like): Los datos a analizar.\n    alpha (float): Nivel de significancia.\n\n    Returns:\n    str: El resultado de la prueba.\n    \"\"\"\n    statistic, p_value = stats.shapiro(data)\n\n    if p_value < alpha:\n        return (\n            \"Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\"\n        )\n    else:\n        return \"Fallamos al rechazar la hipótesis nula. Los datos pueden considerarse normalmente distribuidos.\"\n\n\nresult_fiction = shapiro_test(fiction_bestsellers[\"Reviews\"])\nresult_nonfiction = shapiro_test(nonfiction_bestsellers[\"Reviews\"])\n\nprint(\"Para bestsellers de ficción:\", result_fiction)\nprint(\"Para bestsellers de no ficción:\", result_nonfiction)\n```\n\nEstudiemos la relación entre las varianzas de cada grupo.\n\n```{python}\n# varianza de los grupos\nbestsellers.groupby([\"Genre\"])[\"Reviews\"].var()\n```\n\n```{python}\n# Realiza el Test de Levene\nstatistic, p_value = stats.levene(\n    fiction_bestsellers[\"User Rating\"], nonfiction_bestsellers[\"User Rating\"]\n)\n\n# Nivel de significancia\nalpha = 0.05\n\n# Comprueba la significancia\nif p_value < alpha:\n    print(\"Rechazamos la hipótesis nula. Las varianzas no son similares\")\nelse:\n    print(\"Fallamos al rechazar la hipótesis nula. Las varianzas son similares\")\n```\n\n### 1. Seleccionamos la hipotesis y el nivel de significancia\n\nH0: El número de Reviews medio de los libros de ficción es igual que el de los libros de no ficción\n\nHa: El número de Reviews medio de los libros de ficción es diferente que el de los libros de no ficción\n\nalpha = 0.05\n\n### 2. Identificamos el tipo de test\n\nDeseamos comparar las medias de dos grupos de nuestra Sample. Por lo que un 2-Sample t-Test parece lo adecuado. Lo primero es ver si se cumplen los requisitos del test.\n\n#### 2.1 Requisitos del test\n[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 48\nSection: 2-Sample t-Tests]\n- Tenemos un Sample representativo de la población? Si.\n- Los datos son continuos? Si.\n- Las muestras siguen una distribución normal o hay más de 15 observaciones\n  - No, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema del límite central podemos renunciar al supuesto de normalidad.\n- Los grupos son independientes? Si.\n- Las varianzas son iguales (o al menos similares)?\n  - No.\n\n\nLas varianzas no son similares y su relación es de más del doble. Vamos a reliazar un test tipo **Welch's t-test**.\n\nPara realizar el test vamos a usar [scipy.stats.ttest_ind](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html).\nPara realizar este test, es necesario definir el parametro *equal_varbool* como *False*.\n\n```{python}\n# Realiza el test t de Welch (equal_var=False)\nstatistic, p_value = stats.ttest_ind(\n    nonfiction_bestsellers[\"Reviews\"], fiction_bestsellers[\"Reviews\"], equal_var=False\n)\n\n# Imprime los resultados\nprint(\"Valor p:\", p_value)\n\n# Comprueba la significancia\nalpha = 0.05  # Nivel de significancia\nif p_value < alpha:\n    print(\n        \"Rechazamos la hipótesis nula: Hay diferencias significativas entre los grupos.\"\n    )\nelse:\n    print(\n        \"No podemos rechazar la hipótesis nula: No hay diferencias significativas entre los grupos.\"\n    )\n```\n\nLos libros del género de ficción obtienen más Reviews que los libros de no ficción.\n\n## ¿Los géneros difieren en términos de Price?\n\nRepresentamos gráficamente los datos.\n\n```{python}\nsns.kdeplot(fiction_bestsellers[\"Price\"], fill=True, color=\"r\")\nsns.kdeplot(nonfiction_bestsellers[\"Price\"], fill=True, color=\"b\")\nplt.legend([\"Fiction\", \"Non Fiction\"])\nplt.xlabel(\"User Rating\")\nplt.ylabel(\"Density\")\nplt.show()\n```\n\n```{python}\n# Calcular el coeficiente de asimetría\nskewness = stats.skew(bestsellers[\"Price\"])\nprint(\"Coeficiente de asimetría:\", skewness)\n\nif skewness > 0:\n    print(\"La distribución está positivamente sesgada.\")\nelif skewness < 0:\n    print(\"La distribución está negativamente sesgada.\")\nelse:\n    print(\"La distribución es simétrica.\")\n```\n\nRealizamos un test de normalidad para cada grupo:\n\n```{python}\nfrom scipy import stats\n\n\ndef shapiro_test(data, alpha=0.05):\n    \"\"\"\n    Realiza la prueba de Shapiro-Wilk para verificar la normalidad de los datos.\n\n    Parameters:\n    data (array-like): Los datos a analizar.\n    alpha (float): Nivel de significancia.\n\n    Returns:\n    str: El resultado de la prueba.\n    \"\"\"\n    statistic, p_value = stats.shapiro(data)\n\n    if p_value < alpha:\n        return (\n            \"Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\"\n        )\n    else:\n        return \"Fallamos al rechazar la hipótesis nula. Los datos pueden considerarse normalmente distribuidos.\"\n\n\nresult_fiction = shapiro_test(fiction_bestsellers[\"Price\"])\nresult_nonfiction = shapiro_test(nonfiction_bestsellers[\"Price\"])\n\nprint(\"Para bestsellers de ficción:\", result_fiction)\nprint(\"Para bestsellers de no ficción:\", result_nonfiction)\n```\n\nEstudiemos la relación entre las varianzas de cada grupo.\n\n```{python}\n# Realiza el Test de Levene\nstatistic, p_value = stats.levene(\n    fiction_bestsellers[\"Price\"], nonfiction_bestsellers[\"Price\"]\n)\n\n# Nivel de significancia\nalpha = 0.05\n\n# Comprueba la significancia\nif p_value < alpha:\n    print(\"Rechazamos la hipótesis nula. Las varianzas no son similares\")\nelse:\n    print(\"Fallamos al rechazar la hipótesis nula. Las varianzas son similares\")\n```\n\n```{python}\n# varianza de los grupos\nbestsellers.groupby([\"Genre\"])[\"Price\"].var()\n```\n\n### 1. Seleccionamos la hipotesis y el nivel de significancia\n\nH0: El precio medio de los libros de ficción es igual que el de los libros de no ficción\n\nHa: El precio medio de los libros de ficción es diferente que el de los libros de no ficción\n\nalpha = 0.05\n\n### 2. Identificamos el tipo de test\n\nDeseamos comparar las medias de dos grupos de nuestra Sample. Por lo que un 2-Sample t-Test parece lo adecuado. Lo primero es ver si se cumplen los requisitos del test.\n\n#### 2.1 Requisitos del test\n[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 48\nSection: 2-Sample t-Tests]\n- Tenemos un Sample representativo de la población? Si.\n- Los datos son continuos? Si.\n- Las muestras siguen una distribución normal o hay más de 15 observaciones\n  - No, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema del límite central podemos renunciar al supuesto de normalidad.\n- Los grupos son independientes? Si.\n- Las varianzas son iguales (o al menos similares)? Si.\n\nSe cumplen los requisitos para realizar un **2-Sample t-Test**.\n\nPara realizar el test vamos a usar [scipy.stats.ttest_ind](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html).\n\n```{python}\n# Realiza el test t\nstatistic, p_value = stats.ttest_ind(\n    nonfiction_bestsellers[\"Price\"], fiction_bestsellers[\"Price\"]\n)\n\n# Imprime los resultados\nprint(\"Valor p:\", p_value)\n\n# Comprueba la significancia\nalpha = 0.05  # Nivel de significancia\nif p_value < alpha:\n    print(\n        \"Rechazamos la hipótesis nula: Hay diferencias significativas entre los grupos.\"\n    )\nelse:\n    print(\n        \"No podemos rechazar la hipótesis nula: No hay diferencias significativas entre los grupos.\"\n    )\n```\n\nEl precio no es dependiente del género.\n\n","srcMarkdownNoYaml":"\n\n\n\n## 2. Data Understanding\n### 2.1 Donwload data from Kaggle\n\n```{python}\n# Import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n```\n\nDownload dataset\n\n```{python}\nfrom kaggle import KaggleApi\nimport os\n\n# Nombre del archivo del dataset en Kaggle\ndataset_name = \"bestsellers with categories.csv\"\n# ID del dataset en Kaggle\ndataset_id = \"sootersaalu/amazon-top-50-bestselling-books-2009-2019/\"\n\n# Directorio de destino\ndownload_path = \"./data/\"\n\n# Verificar si el archivo ya existe en la carpeta de destino\nlist_of_files = os.listdir(download_path)\nif any(dataset_name in filename for filename in list_of_files):\n    print(\"El archivo ya existe \" + download_path)\nelse:\n    # Autenticar con la API de Kaggle\n    api = KaggleApi()\n    api.authenticate()\n\n    # Descargar el dataset\n    api.dataset_download_files(dataset_id, path=download_path, unzip=True)\n```\n\n### 2.2 Data description\n\n```{python}\ndf = pd.read_csv(download_path + dataset_name)\ndf.head(30)\n```\n\n- Name\n  - Título del libro\n  - Unidad: texto (categoría)\n- Author\n  - Nombre del autor\n  - Unidad: texto (categoría)\n- User Rating\n  - Calificación promedio del libro por los usuarios\n  - Unidad: número entre 0 y 5 (con decimales)\n- Reviews\n  - Número de reseñas\n  - Unidad: número entero\n- Price\n  - Precio del libro\n  - Unidad: número entero\n- Year\n  - Año en el que el libro fue de los más vendidos\n  - Unidad: año (número entero)\n- Genre\n  - Género del libro simplificado (Fiction o Non Fiction)\n  - Unidad: categorico con dos valores posibles\n\n## 3. Data preparation\n\n### 3.1 Typecasting\n\n## 1. Business Understanding\n\ndataset source: https://www.kaggle.com/datasets/sootersaalu/amazon-top-50-bestselling-books-2009-2019/data\n\n### Context\nDatos sobre los 50 libros más vendidos en Amazon de 2009 a 2019. \n\n### Hypothesis to Test\n\nVamos a responder a las siguientes preguntas con validez estadística:\n\n- ¿Los géneros difieren en User Rating?\n- ¿Los géneros difieren en número de Reviews?\n- ¿Los géneros difieren en términos de precio?\n\n```{python}\n# comprobamos el tipo de datos de las columnas\ndf.dtypes\n```\n\n```{python}\ncolumnas_categoricas = [\"Genre\", \"Name\", \"Author\"]\ndf[columnas_categoricas] = df[columnas_categoricas].astype(\"category\")\n```\n\n```{python}\ndf.dtypes\n```\n\n### 3.2 Handling Duplicates\n\nComprobar si hay autores o títulos iguales pero escritos diferente.\n\n```{python}\nfrom fuzzywuzzy import fuzz\n\n\n# Función para encontrar nombres de autores similares\ndef encontrar_similares(df, columna):\n    autores = df[columna].unique()\n    duplicados = []\n\n    for i, autor1 in enumerate(autores):\n        for autor2 in autores[i + 1 :]:\n            ratio = fuzz.ratio(autor1, autor2)\n            if ratio > 90:  # Puedes ajustar este umbral según tu criterio\n                duplicados.append((autor1, autor2))\n\n    return duplicados\n\n\n```\n\n```{python}\n# Encuentra nombres de autores similares\nduplicados = encontrar_similares(df, \"Author\")\n\nprint(\n    \"Nombres de autores que se refieren al mismo autor pero están escritos diferente:\"\n)\nfor dup in duplicados:\n    print(dup)\n```\n\n```{python}\n# Replace the names of the Authors with the correct ones\ndf = df.replace(\"George R. R. Martin\", \"George R.R. Martin\")\ndf = df.replace(\"J. K. Rowling\", \"J.K. Rowling\")\n```\n\n```{python}\n# Encuentra nombres de títulos similares\nduplicados = encontrar_similares(df, \"Name\")\n\nprint(\n    \"Nombres de autores que se refieren al mismo autor pero están escritos diferente:\"\n)\nfor dup in duplicados:\n    print(dup)\n```\n\n```{python}\n# Replace the names of the Authors with the correct ones\ndf = df.replace(\n    \"The 5 Love Languages: The Secret to Love That Lasts\",\n    \"The 5 Love Languages: The Secret to Love that Lasts\",\n)\ndf = df.replace(\n    \"The Girl Who Played with Fire (Millennium Series)\",\n    \"The Girl Who Played with Fire (Millennium)\",\n)\n```\n\n```{python}\ndf\n```\n\n```{python}\n# número de filas duplicadas\ndf.duplicated().sum()\n```\n\nEs normal no encontrar duplicados en este caso, hay libros que se repiten pero es imposible que coincidan en \"Year\". No es un error por si mismo. Pero hay un problema. Las \"Reviews\" deberían ser las que el libro tenia el año en el que fue de los mas vendidos. En lugar de eso son las del último año. Esto puede deberse a que el autor del dataset no tuvo acceso al historial de las reseñas.\n\nEs importante tener en cuenta esto para el análisis.\n\nVamos a utilizar unicamente la muestra más reciente de cada libro.\n\n```{python}\n# todos los libros con el titulo repetido\ndf[df.duplicated(\"Name\")].head(20)\n```\n\n```{python}\n# Drop duplicates\nbestsellers = df.drop_duplicates(subset=\"Name\", keep=\"last\")\nbestsellers\n```\n\nResumen:\n- Hemos corregido los errores ortográficos de los títulos y autores.\n- Hemos seleccionado las muestras más recientes de cada libro.\n\nHemos reducido el tamaño del dataset de 550 a 349 muestras.\n\n### 3.3 Outlier Analysis\n\n#### 3.3.2 Usando boxplot y IQR \nIQR: El rango intercuartil (IQR) es la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1). Los valores que caen por debajo de Q1 - 1.5 * IQR o por encima de Q3 + 1.5 * IQR se consideran outliers.\n\nLos valores fuera del de este rango, son los que se representa como puntos en los bloxpots.\n\n```{python}\nimport plotly.express as px\n\nselected_columns = [\"Reviews\", \"Price\"]\n\nfor column in selected_columns:\n    fig = px.box(df, x=column, title=f\"Boxplot of {column}\")\n    fig.update_layout(title_x=0.5)  # Centra el título\n    fig.show()\n```\n\nObservaciones:\n\n- age: no se detectan outliers\n- BMI: existen outliers, personas con una alta obesidad\n- charges: existen outliers, personas con cargos muy altos al seguro\n\n### 3.4 Zero & Near Zero Variance Features\n\n```{python}\nbestsellers.describe()\n```\n\nVariables númericas\n\n```{python}\nselected_columns = [\"User Rating\", \"Reviews\", \"Price\"]\n\n# Calcular la varianza de cada columna\nvariances = bestsellers[selected_columns].var()\n\n# Definir un umbral para la varianza\nthreshold = 0.1\n\n# Identificar las columnas con varianza cercana a cero o muy pequeña\nzero_variance_cols = variances[variances <= threshold].index\n\nprint(\"Columnas con Zero & Near Zero Variance:\")\nprint(zero_variance_cols)\n```\n\nVariables categoricas. No tiene sentido en este analisis en este caso.\n\nObserviaciones:\n\n- No se detectan variables con Zero & Near Zero Variance\n\n### 3.5 Missing values\n\n```{python}\nbestsellers.isnull().sum()\n```\n\nObserviaciones:\n\n- No hay Missing values\n\n# 4. Hipothesis Testing\n\nVamos a responder a las siguientes preguntas con validez estadística:\n- ¿Los géneros difieren en User Rating?\n- ¿Los géneros difieren en número de Reviews?\n- ¿Los géneros difieren en términos de precio?\n\n## ¿Los géneros difieren en User Rating?\n\nVamos a crear una variable para cada grupo de interes y representarlos gráficamente.\n\n```{python}\nfiction_bestsellers = bestsellers[bestsellers[\"Genre\"] == \"Fiction\"]\nnonfiction_bestsellers = bestsellers[bestsellers[\"Genre\"] == \"Non Fiction\"]\n```\n\n```{python}\nsns.kdeplot(fiction_bestsellers[\"User Rating\"], fill=True, color=\"r\")\nsns.kdeplot(nonfiction_bestsellers[\"User Rating\"], fill=True, color=\"b\")\nplt.legend([\"Fiction\", \"Non Fiction\"])\nplt.xlabel(\"User Rating\")\nplt.ylabel(\"Density\")\nplt.show()\n```\n\n```{python}\n# Calcular el coeficiente de asimetría\nskewness = stats.skew(bestsellers[\"User Rating\"])\nprint(\"Coeficiente de asimetría:\", skewness)\n\nif skewness > 0:\n    print(\"La distribución está positivamente sesgada.\")\nelif skewness < 0:\n    print(\"La distribución está negativamente sesgada.\")\nelse:\n    print(\"La distribución es simétrica.\")\n```\n\nNúmero de observaciones para cada grupo:\n\n```{python}\nbestsellers[\"Genre\"].value_counts()\n```\n\nRealizamos un test de normalidad para cada grupo:\n\n```{python}\nfrom scipy import stats\n\n\ndef shapiro_test(data, alpha=0.05):\n    \"\"\"\n    Realiza la prueba de Shapiro-Wilk para verificar la normalidad de los datos.\n\n    Parameters:\n    data (array-like): Los datos a analizar.\n    alpha (float): Nivel de significancia.\n\n    Returns:\n    str: El resultado de la prueba.\n    \"\"\"\n    statistic, p_value = stats.shapiro(data)\n\n    if p_value < alpha:\n        return (\n            \"Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\"\n        )\n    else:\n        return \"Fallamos al rechazar la hipótesis nula. Los datos pueden considerarse normalmente distribuidos.\"\n\n\nresult_fiction = shapiro_test(fiction_bestsellers[\"User Rating\"])\nresult_nonfiction = shapiro_test(nonfiction_bestsellers[\"User Rating\"])\n\nprint(\"Para bestsellers de ficción:\", result_fiction)\nprint(\"Para bestsellers de no ficción:\", result_nonfiction)\n```\n\nEstudiemos la relación entre las varianzas de cada grupo.\n\n```{python}\n# Realiza el Test de Levene\nstatistic, p_value = stats.levene(\n    fiction_bestsellers[\"User Rating\"], nonfiction_bestsellers[\"User Rating\"]\n)\n\n# Nivel de significancia\nalpha = 0.05\n\n# Comprueba la significancia\nif p_value < alpha:\n    print(\"Rechazamos la hipótesis nula. Las varianzas no son similares\")\nelse:\n    print(\"Fallamos al rechazar la hipótesis nula. Las varianzas son similares\")\n```\n\n```{python}\n# varianza de los grupos\nbestsellers.groupby([\"Genre\"])[\"User Rating\"].var()\n```\n\n### 1. Seleccionamos la hipotesis y el nivel de significancia\n\nH0: El \"User Rating\" de los libros de ficción es igual que el de los libros de no ficción\n\nHa: El \"User Rating\" de los libros de ficción es diferente que el de los libros de no ficción\n\nalpha = 0.05\n\n### 2. Identificamos el tipo de test\n\nDeseamos comparar las medias de dos grupos de nuestra Sample. Por lo que un 2-Sample t-Test parece lo adecuado. Lo primero es ver si se cumplen los requisitos del test.\n\n#### 2.1 Requisitos del test\n[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 48\nSection: 2-Sample t-Tests]\n- Tenemos un Sample representativo de la población? Si.\n- Los datos son continuos? \n  - En este contexto, los \"User Rating\" que van de 0 a 5 con un único decimal pueden considerarse como datos continuos. Sim embargo, observando las gráficas, vemos que la mayoría de los valores se encuetran en un intervalor muy pequeño (mayores a 4.0). Esto dificulta el poder considerarlo continuos.\n- Las muestras siguen una distribución normal o hay más de 15 observaciones\n  - No, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema del límite central podemos renunciar al supuesto de normalidad.\n- Los grupos son independientes? Si.\n- Las varianzas son iguales (o al menos similares)?\n  - No.\n\n\nPor la falta de continuidad en los datos, vamos a realizar un **test no paramétrico Mann-Whitney**.\n\n[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 341\nSection: Analyzing Likert Scale Data]\n\nPara realizar el test vamos a usar [scipy.stats.mannwhitneyu](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html)\n\n```{python}\n# Realiza el test de Mann-Whitney\nstatistic, p_value = stats.mannwhitneyu(\n    nonfiction_bestsellers[\"User Rating\"], fiction_bestsellers[\"User Rating\"]\n)\n\n# Imprime los resultados\nprint(\"Valor p:\", p_value)\n\n# Comprueba la significancia\nalpha = 0.05  # Nivel de significancia\nif p_value < alpha:\n    print(\n        \"Rechazamos la hipótesis nula. Hay diferencias significativas entre los grupos.\"\n    )\nelse:\n    print(\n        \"Fallamos al rechazar la hipótesis nula. No hay diferencias significativas entre los grupos.\"\n    )\n```\n\n## ¿Los géneros difieren en número de Reviews?\n\nRepresentamos gráficamente los grupos de interés.\n\n```{python}\nsns.kdeplot(fiction_bestsellers[\"Reviews\"], fill=True, color=\"r\")\nsns.kdeplot(nonfiction_bestsellers[\"Reviews\"], fill=True, color=\"b\")\nplt.legend([\"Fiction\", \"Non Fiction\"])\nplt.xlabel(\"User Rating\")\nplt.ylabel(\"Density\")\nplt.show()\n```\n\n```{python}\n# Calcular el coeficiente de asimetría\nskewness = stats.skew(bestsellers[\"Reviews\"])\nprint(\"Coeficiente de asimetría:\", skewness)\n\nif skewness > 0:\n    print(\"La distribución está positivamente sesgada.\")\nelif skewness < 0:\n    print(\"La distribución está negativamente sesgada.\")\nelse:\n    print(\"La distribución es simétrica.\")\n```\n\nNúmero de observaciones para cada grupo:\n\n```{python}\nbestsellers[\"Genre\"].value_counts()\n```\n\nRealizamos un test de normalidad para cada grupo:\n\n```{python}\nfrom scipy import stats\n\n\ndef shapiro_test(data, alpha=0.05):\n    \"\"\"\n    Realiza la prueba de Shapiro-Wilk para verificar la normalidad de los datos.\n\n    Parameters:\n    data (array-like): Los datos a analizar.\n    alpha (float): Nivel de significancia.\n\n    Returns:\n    str: El resultado de la prueba.\n    \"\"\"\n    statistic, p_value = stats.shapiro(data)\n\n    if p_value < alpha:\n        return (\n            \"Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\"\n        )\n    else:\n        return \"Fallamos al rechazar la hipótesis nula. Los datos pueden considerarse normalmente distribuidos.\"\n\n\nresult_fiction = shapiro_test(fiction_bestsellers[\"Reviews\"])\nresult_nonfiction = shapiro_test(nonfiction_bestsellers[\"Reviews\"])\n\nprint(\"Para bestsellers de ficción:\", result_fiction)\nprint(\"Para bestsellers de no ficción:\", result_nonfiction)\n```\n\nEstudiemos la relación entre las varianzas de cada grupo.\n\n```{python}\n# varianza de los grupos\nbestsellers.groupby([\"Genre\"])[\"Reviews\"].var()\n```\n\n```{python}\n# Realiza el Test de Levene\nstatistic, p_value = stats.levene(\n    fiction_bestsellers[\"User Rating\"], nonfiction_bestsellers[\"User Rating\"]\n)\n\n# Nivel de significancia\nalpha = 0.05\n\n# Comprueba la significancia\nif p_value < alpha:\n    print(\"Rechazamos la hipótesis nula. Las varianzas no son similares\")\nelse:\n    print(\"Fallamos al rechazar la hipótesis nula. Las varianzas son similares\")\n```\n\n### 1. Seleccionamos la hipotesis y el nivel de significancia\n\nH0: El número de Reviews medio de los libros de ficción es igual que el de los libros de no ficción\n\nHa: El número de Reviews medio de los libros de ficción es diferente que el de los libros de no ficción\n\nalpha = 0.05\n\n### 2. Identificamos el tipo de test\n\nDeseamos comparar las medias de dos grupos de nuestra Sample. Por lo que un 2-Sample t-Test parece lo adecuado. Lo primero es ver si se cumplen los requisitos del test.\n\n#### 2.1 Requisitos del test\n[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 48\nSection: 2-Sample t-Tests]\n- Tenemos un Sample representativo de la población? Si.\n- Los datos son continuos? Si.\n- Las muestras siguen una distribución normal o hay más de 15 observaciones\n  - No, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema del límite central podemos renunciar al supuesto de normalidad.\n- Los grupos son independientes? Si.\n- Las varianzas son iguales (o al menos similares)?\n  - No.\n\n\nLas varianzas no son similares y su relación es de más del doble. Vamos a reliazar un test tipo **Welch's t-test**.\n\nPara realizar el test vamos a usar [scipy.stats.ttest_ind](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html).\nPara realizar este test, es necesario definir el parametro *equal_varbool* como *False*.\n\n```{python}\n# Realiza el test t de Welch (equal_var=False)\nstatistic, p_value = stats.ttest_ind(\n    nonfiction_bestsellers[\"Reviews\"], fiction_bestsellers[\"Reviews\"], equal_var=False\n)\n\n# Imprime los resultados\nprint(\"Valor p:\", p_value)\n\n# Comprueba la significancia\nalpha = 0.05  # Nivel de significancia\nif p_value < alpha:\n    print(\n        \"Rechazamos la hipótesis nula: Hay diferencias significativas entre los grupos.\"\n    )\nelse:\n    print(\n        \"No podemos rechazar la hipótesis nula: No hay diferencias significativas entre los grupos.\"\n    )\n```\n\nLos libros del género de ficción obtienen más Reviews que los libros de no ficción.\n\n## ¿Los géneros difieren en términos de Price?\n\nRepresentamos gráficamente los datos.\n\n```{python}\nsns.kdeplot(fiction_bestsellers[\"Price\"], fill=True, color=\"r\")\nsns.kdeplot(nonfiction_bestsellers[\"Price\"], fill=True, color=\"b\")\nplt.legend([\"Fiction\", \"Non Fiction\"])\nplt.xlabel(\"User Rating\")\nplt.ylabel(\"Density\")\nplt.show()\n```\n\n```{python}\n# Calcular el coeficiente de asimetría\nskewness = stats.skew(bestsellers[\"Price\"])\nprint(\"Coeficiente de asimetría:\", skewness)\n\nif skewness > 0:\n    print(\"La distribución está positivamente sesgada.\")\nelif skewness < 0:\n    print(\"La distribución está negativamente sesgada.\")\nelse:\n    print(\"La distribución es simétrica.\")\n```\n\nRealizamos un test de normalidad para cada grupo:\n\n```{python}\nfrom scipy import stats\n\n\ndef shapiro_test(data, alpha=0.05):\n    \"\"\"\n    Realiza la prueba de Shapiro-Wilk para verificar la normalidad de los datos.\n\n    Parameters:\n    data (array-like): Los datos a analizar.\n    alpha (float): Nivel de significancia.\n\n    Returns:\n    str: El resultado de la prueba.\n    \"\"\"\n    statistic, p_value = stats.shapiro(data)\n\n    if p_value < alpha:\n        return (\n            \"Rechazamos la hipótesis nula. Los datos no siguen una distribución normal.\"\n        )\n    else:\n        return \"Fallamos al rechazar la hipótesis nula. Los datos pueden considerarse normalmente distribuidos.\"\n\n\nresult_fiction = shapiro_test(fiction_bestsellers[\"Price\"])\nresult_nonfiction = shapiro_test(nonfiction_bestsellers[\"Price\"])\n\nprint(\"Para bestsellers de ficción:\", result_fiction)\nprint(\"Para bestsellers de no ficción:\", result_nonfiction)\n```\n\nEstudiemos la relación entre las varianzas de cada grupo.\n\n```{python}\n# Realiza el Test de Levene\nstatistic, p_value = stats.levene(\n    fiction_bestsellers[\"Price\"], nonfiction_bestsellers[\"Price\"]\n)\n\n# Nivel de significancia\nalpha = 0.05\n\n# Comprueba la significancia\nif p_value < alpha:\n    print(\"Rechazamos la hipótesis nula. Las varianzas no son similares\")\nelse:\n    print(\"Fallamos al rechazar la hipótesis nula. Las varianzas son similares\")\n```\n\n```{python}\n# varianza de los grupos\nbestsellers.groupby([\"Genre\"])[\"Price\"].var()\n```\n\n### 1. Seleccionamos la hipotesis y el nivel de significancia\n\nH0: El precio medio de los libros de ficción es igual que el de los libros de no ficción\n\nHa: El precio medio de los libros de ficción es diferente que el de los libros de no ficción\n\nalpha = 0.05\n\n### 2. Identificamos el tipo de test\n\nDeseamos comparar las medias de dos grupos de nuestra Sample. Por lo que un 2-Sample t-Test parece lo adecuado. Lo primero es ver si se cumplen los requisitos del test.\n\n#### 2.1 Requisitos del test\n[Book:Hypothesis Testing An Intuitive Guide For Making Data Driven Decisions\nPage: 48\nSection: 2-Sample t-Tests]\n- Tenemos un Sample representativo de la población? Si.\n- Los datos son continuos? Si.\n- Las muestras siguen una distribución normal o hay más de 15 observaciones\n  - No, las muestras no siguen una distribución normal. Pero hay más de 15 observaciones en cada grupo, gracias al teorema del límite central podemos renunciar al supuesto de normalidad.\n- Los grupos son independientes? Si.\n- Las varianzas son iguales (o al menos similares)? Si.\n\nSe cumplen los requisitos para realizar un **2-Sample t-Test**.\n\nPara realizar el test vamos a usar [scipy.stats.ttest_ind](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html).\n\n```{python}\n# Realiza el test t\nstatistic, p_value = stats.ttest_ind(\n    nonfiction_bestsellers[\"Price\"], fiction_bestsellers[\"Price\"]\n)\n\n# Imprime los resultados\nprint(\"Valor p:\", p_value)\n\n# Comprueba la significancia\nalpha = 0.05  # Nivel de significancia\nif p_value < alpha:\n    print(\n        \"Rechazamos la hipótesis nula: Hay diferencias significativas entre los grupos.\"\n    )\nelse:\n    print(\n        \"No podemos rechazar la hipótesis nula: No hay diferencias significativas entre los grupos.\"\n    )\n```\n\nEl precio no es dependiente del género.\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"bestsellers_with_categories_hypothesis_testing.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":{"light":"minty","dark":"solar"},"title-block-banner":true,"title":"Exploring Hypothesis Testing: A Series for Beginners","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}